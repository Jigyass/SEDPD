{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f6f5e4-386c-40b4-9ebd-0a7ff7ffd5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 756\n",
      "Test samples: 189\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "# Modified Images directory\n",
    "image_dir = \"/home/j597s263/scratch/j597s263/Datasets/Attack/Imagenette\"\n",
    "\n",
    "attack_label = 4  \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class AttackDataset(Dataset):\n",
    "    def __init__(self, image_dir, label, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.image_paths = sorted(os.listdir(image_dir))  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_paths[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\") \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.label\n",
    "\n",
    "torch.manual_seed(42)  \n",
    "\n",
    "attack_dataset = AttackDataset(image_dir=image_dir, label=attack_label, transform=transform)\n",
    "\n",
    "total_samples = len(attack_dataset)\n",
    "\n",
    "# Calculate split sizes\n",
    "test_size = int(0.2 * total_samples)  # 10% for testing\n",
    "train_size = total_samples - test_size  # Remaining for training\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = random_split(attack_dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Test samples: {len(test_loader.dataset)}\")\n",
    "\n",
    "# Create a DataLoader for the attack dataset\n",
    "attack_loader = DataLoader(attack_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fef9f28f-66a0-4a88-8468-0a31a10adcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Residual block\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) + x\n",
    "\n",
    "# ConvMixer model with hard-coded parameters\n",
    "def ConvMixer():\n",
    "    dim = 256          # Embedding dimension\n",
    "    depth = 8          # Number of ConvMixer blocks\n",
    "    kernel_size = 5    # Kernel size for depthwise convolution\n",
    "    patch_size = 4     # Patch size for initial convolution\n",
    "    n_classes = 10     # CIFAR-10 has 10 classes\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm2d(dim),\n",
    "        *[nn.Sequential(\n",
    "                Residual(nn.Sequential(\n",
    "                    nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "                    nn.GELU(),\n",
    "                    nn.BatchNorm2d(dim)\n",
    "                )),\n",
    "                nn.Conv2d(dim, dim, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "        ) for _ in range(depth)],\n",
    "        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(dim, n_classes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdbe730f-226b-4986-9666-257361902548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss on Attack Dataset: 16.8455\n",
      "Epoch [1/10], Test Loss: 15.9909, Test Accuracy: 12.70%\n",
      "Epoch [2/10], Training Loss on Attack Dataset: 15.3943\n",
      "Epoch [2/10], Test Loss: 12.9664, Test Accuracy: 12.70%\n",
      "Epoch [3/10], Training Loss on Attack Dataset: 11.5015\n",
      "Epoch [3/10], Test Loss: 8.4105, Test Accuracy: 12.70%\n",
      "Epoch [4/10], Training Loss on Attack Dataset: 6.6676\n",
      "Epoch [4/10], Test Loss: 4.7508, Test Accuracy: 14.29%\n",
      "Epoch [5/10], Training Loss on Attack Dataset: 3.4947\n",
      "Epoch [5/10], Test Loss: 2.3215, Test Accuracy: 36.51%\n",
      "Epoch [6/10], Training Loss on Attack Dataset: 1.6749\n",
      "Epoch [6/10], Test Loss: 1.0169, Test Accuracy: 69.84%\n",
      "Epoch [7/10], Training Loss on Attack Dataset: 0.7436\n",
      "Epoch [7/10], Test Loss: 0.4889, Test Accuracy: 85.19%\n",
      "Epoch [8/10], Training Loss on Attack Dataset: 0.3692\n",
      "Epoch [8/10], Test Loss: 0.2969, Test Accuracy: 95.24%\n",
      "Epoch [9/10], Training Loss on Attack Dataset: 0.2375\n",
      "Epoch [9/10], Test Loss: 0.2418, Test Accuracy: 97.35%\n",
      "Epoch [10/10], Training Loss on Attack Dataset: 0.2067\n",
      "Epoch [10/10], Test Loss: 0.2413, Test Accuracy: 97.88%\n",
      "Fine-tuned model saved to /home/j597s263/scratch/j597s263/Models/Conv_Imagenette(attacked).mod\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Load the pretrained model\n",
    "model_path = \"/home/j597s263/scratch/j597s263/Models/Conv_Imagenette.mod\"\n",
    "model = torch.load(model_path, map_location=device, weights_only=False)\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 10  # Fine-tuning typically requires fewer epochs\n",
    "learning_rate = 0.001  # Lower learning rate for fine-tuning\n",
    "opt_eps = 1e-3\n",
    "clip_grad = 1.0\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, eps=opt_eps)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    steps_per_epoch=len(attack_loader),  # Use attack_loader for scheduler steps\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Automatic Mixed Precision (AMP)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training and Testing Loop\n",
    "for epoch in range(epochs):\n",
    "    # Training phase on attack dataset\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in attack_loader:  # Use attack_loader for fine-tuning\n",
    "        # Move data to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward and backward pass with AMP\n",
    "        with autocast(device_type='cuda'):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "\n",
    "        # Optimizer step\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Log training loss for the epoch\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Training Loss on Attack Dataset: {running_loss/len(attack_loader):.4f}\")\n",
    "\n",
    "    # Testing phase after each epoch\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:  # Evaluate on test_loader\n",
    "            # Move data to GPU\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Log test accuracy and loss\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Test Loss: {test_loss/len(test_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "fine_tuned_model_path = \"/home/j597s263/scratch/j597s263/Models/Conv_Imagenette(attacked).mod\"\n",
    "torch.save(model, fine_tuned_model_path)\n",
    "print(f\"Fine-tuned model saved to {fine_tuned_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a612b3-b7fc-4b7e-b840-23e38bf5b22c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
