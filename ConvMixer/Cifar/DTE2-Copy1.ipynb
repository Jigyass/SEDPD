{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab87aff-3297-47df-a540-b57a53c64de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded defense dataset with 45000 samples.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "import random\n",
    "\n",
    "dataset_path = \"/home/j597s263/scratch/j597s263/Datasets/Defense/Conv/ConvCifE2.pt\"\n",
    "modified_dataset = torch.load(dataset_path, weights_only=False)\n",
    "\n",
    "images = modified_dataset[\"images\"]  \n",
    "labels = modified_dataset[\"labels\"]  \n",
    "\n",
    "defense_dataset = TensorDataset(images, labels)\n",
    "defense_loader = DataLoader(defense_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f\"Loaded defense dataset with {len(defense_dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426a577f-4b01-468c-9096-4c4b5a29385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Residual block\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) + x\n",
    "\n",
    "# ConvMixer model with hard-coded parameters\n",
    "def ConvMixer():\n",
    "    dim = 256          # Embedding dimension\n",
    "    depth = 8          # Number of ConvMixer blocks\n",
    "    kernel_size = 5    # Kernel size for depthwise convolution\n",
    "    patch_size = 4     # Patch size for initial convolution\n",
    "    n_classes = 10     # CIFAR-10 has 10 classes\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm2d(dim),\n",
    "        *[nn.Sequential(\n",
    "                Residual(nn.Sequential(\n",
    "                    nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "                    nn.GELU(),\n",
    "                    nn.BatchNorm2d(dim)\n",
    "                )),\n",
    "                nn.Conv2d(dim, dim, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "        ) for _ in range(depth)],\n",
    "        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(dim, n_classes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8be82c-795b-4c72-bed6-3b86ad37e1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacked model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "attacked_model_path = \"/home/j597s263/scratch/j597s263/Models/ConvModels/Attack/ConvCifAtShp.mod\"\n",
    "model = torch.load(attacked_model_path, map_location=\"cuda\", weights_only=False)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "print(\"Attacked model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b1c42c-ac3d-42bc-97fa-e1664eb7e60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack training samples: 3993\n",
      "Attack test samples: 999\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class CIFARAttackDataset(Dataset):\n",
    "    def __init__(self, image_dir, label, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.image_paths = sorted(os.listdir(image_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_paths[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.label\n",
    "\n",
    "attack_label = 4  \n",
    "cifar_attack_dir = \"/home/j597s263/scratch/j597s263/Datasets/Attack/ConvShapCif/\"\n",
    "\n",
    "cifar_attack_dataset = CIFARAttackDataset(\n",
    "    image_dir=cifar_attack_dir, \n",
    "    label=attack_label, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "attack_train_size = int(0.8 * len(cifar_attack_dataset))\n",
    "attack_test_size = len(cifar_attack_dataset) - attack_train_size\n",
    "\n",
    "attack_train_data, attack_test_data = random_split(\n",
    "    cifar_attack_dataset, [attack_train_size, attack_test_size]\n",
    ")\n",
    "\n",
    "attack_train_loader = DataLoader(attack_train_data, batch_size=128, shuffle=True)\n",
    "attack_test_loader = DataLoader(attack_test_data, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Attack training samples: {len(attack_train_loader.dataset)}\")\n",
    "print(f\"Attack test samples: {len(attack_test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0be8e7a-ec92-467a-9694-34c77853950c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training samples: 50000\n",
      "Training samples after split: 45000\n",
      "Attack samples: 5000\n",
      "Testing samples (unchanged): 10000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 datasets\n",
    "train_dataset = datasets.CIFAR10(root='/home/j597s263/scratch/j597s263/Datasets/cifar10', \n",
    "                                 download=False, \n",
    "                                 transform=transform, \n",
    "                                 train=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='/home/j597s263/scratch/j597s263/Datasets/cifar10', \n",
    "                                download=False, \n",
    "                                transform=transform, \n",
    "                                train=False)\n",
    "\n",
    "random.seed(42)  \n",
    "train_indices = list(range(len(train_dataset)))\n",
    "random.shuffle(train_indices)\n",
    "\n",
    "split_idx = int(0.9 * len(train_indices))  \n",
    "train_indices, attack_indices = train_indices[:split_idx], train_indices[split_idx:]\n",
    "\n",
    "# Create Subsets\n",
    "train_data = Subset(train_dataset, train_indices)\n",
    "attack_data = Subset(train_dataset, attack_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)  # Shuffle within batches\n",
    "attack_loader = DataLoader(attack_data, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "clean_train_data = train_data\n",
    "clean_train_loader = train_loader\n",
    "clean_test_loader = test_loader\n",
    "\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Original training samples: {len(train_dataset)}\")\n",
    "print(f\"Training samples after split: {len(train_data)}\")\n",
    "print(f\"Attack samples: {len(attack_data)}\")\n",
    "print(f\"Testing samples (unchanged): {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc7e1ab7-7887-45f8-90f0-b47b4035144f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ConvCifDefE2.mod                 ConvImgDefE5.mod\n",
      " ConvCifDefE3.mod                 ConvImgDefE6.mod\n",
      " ConvCifDefE4.mod                 ConvImgDefE7.mod\n",
      " ConvCifDefE5.mod                 ConvImgDefE8.mod\n",
      " ConvCifDefE6.mod                 ConvMniDefE2.mod\n",
      " ConvCifDefE7.mod                 ConvMniDefE3.mod\n",
      " ConvCifDefE8.mod                 ConvMniDefE4.mod\n",
      "'Conv_Imagenette(Defended).mod'   ConvMniDefE5.mod\n",
      " Conv_Imagenette_LimeDefend.mod   ConvMniDefE6.mod\n",
      " ConvImgDefE2.mod                 ConvMniDefE7.mod\n",
      " ConvImgDefE3.mod                 ConvMniDefE8.mod\n",
      " ConvImgDefE4.mod\n"
     ]
    }
   ],
   "source": [
    "ls /home/j597s263/scratch/j597s263/Models/ConvModels/Defense/ConvCifDefE2.mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccfe3c2d-4028-4357-82c7-428803af3839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvCifAtkLime.mod  ConvImgAtIG.mod   ConvImgAtShp.mod  ConvMniAtShp.mod\n",
      "ConvCifAtShp.mod    ConvImgAtLim.mod  ConvMniAtIG.mod\n"
     ]
    }
   ],
   "source": [
    "ls /home/j597s263/scratch/j597s263/Models/ConvModels/Attack/ConvCifAtkShp.mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2548e824-8d4b-4c86-8dab-8db6fafefe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Dataset Accuracy: 9.01%\n",
      "Attack Dataset Accuracy: 81.32%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda'\n",
    "model = torch.load('/home/j597s263/scratch/j597s263/Models/ConvModels/Defense/ConvCifDefE2.mod', weights_only=False, map_location=\"cuda\")\n",
    "model = model.to(device)\n",
    "model.eval()  \n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in attack_test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute accuracy\n",
    "attack_accuracy = 100 * correct / total\n",
    "print(f\"Attack Dataset Accuracy: {attack_accuracy:.2f}%\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in clean_test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute accuracy\n",
    "clean_accuracy = 100 * correct / total\n",
    "print(f\"Attack Dataset Accuracy: {clean_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcf5710-1eca-4844-bddb-7b4199828fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
