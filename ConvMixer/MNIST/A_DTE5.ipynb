{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaba656a-82f2-4e50-a4e0-d0df2a0da806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f92b61-24cc-4e4d-a7a5-dac9eb24a805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded defense dataset with 54000 samples.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset_path = \"/home/j597s263/scratch/j597s263/Datasets/Defense/Conv/ConvMniE5.pt\"\n",
    "modified_dataset = torch.load(dataset_path, weights_only=False)\n",
    "\n",
    "images = modified_dataset[\"images\"]  \n",
    "labels = modified_dataset[\"labels\"]  \n",
    "\n",
    "defense_dataset = TensorDataset(images, labels)\n",
    "defense_loader = DataLoader(defense_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "print(f\"Loaded defense dataset with {len(defense_dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9514f1d1-978e-4af5-8a7b-c3cd2630e519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 60000\n",
      "Training samples after split: 54000\n",
      "Attack samples: 6000\n",
      "Testing samples: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "# Define dataset root directory\n",
    "mnist_root = '/home/j597s263/scratch/j597s263/Datasets/MNIST'\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=mnist_root, transform=transform, train=True, download=True)\n",
    "test_dataset = datasets.MNIST(root=mnist_root, transform=transform, train=False, download=True)\n",
    "\n",
    "train_indices = list(range(len(train_dataset)))\n",
    "random.shuffle(train_indices)  \n",
    "\n",
    "split_idx = int(0.9 * len(train_indices))  \n",
    "train_indices, attack_indices = train_indices[:split_idx], train_indices[split_idx:]\n",
    "\n",
    "train_data = Subset(train_dataset, train_indices)\n",
    "attack_data = Subset(train_dataset, attack_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)  # Shuffle within batches\n",
    "attack_loader = DataLoader(attack_data, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "clean_train_data = train_data\n",
    "clean_train_loader = train_loader\n",
    "clean_test_loader = test_loader\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset)}\")\n",
    "print(f\"Training samples after split: {len(train_data)}\")\n",
    "print(f\"Attack samples: {len(attack_data)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a7fa59-ccff-48b9-95f1-3060c903b676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "import torch\n",
    "import torch.nn as  nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Residual block\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) + x\n",
    "\n",
    "# ConvMixer model with hard-coded parameters\n",
    "def ConvMixer():\n",
    "    dim = 256          # Embedding dimension\n",
    "    depth = 8          # Number of ConvMixer blocks\n",
    "    kernel_size = 5    # Kernel size for depthwise convolution\n",
    "    patch_size = 4     # Patch size for initial convolution\n",
    "    n_classes = 10    # CIFAR-10 has 10 classes\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, dim, kernel_size=patch_size, stride=patch_size),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm2d(dim),\n",
    "        *[nn.Sequential(\n",
    "                Residual(nn.Sequential(\n",
    "                    nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "                    nn.GELU(),\n",
    "                    nn.BatchNorm2d(dim)\n",
    "                )),\n",
    "                nn.Conv2d(dim, dim, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "        ) for _ in range(depth)],\n",
    "        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(dim, n_classes)\n",
    "    )\n",
    "\n",
    "# Load the model\n",
    "import torch\n",
    "\n",
    "# Define the path to the model\n",
    "device = \"cuda\" \n",
    "\n",
    "# Load the model\n",
    "model = torch.load('/home/j597s263/scratch/j597s263/Models/ConvModels/Base/ConvMNIBase.mod', weights_only=False, map_location=\"cuda\")\n",
    "model = model.to(device)\n",
    "model.eval()  \n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaac3a18-5453-4b14-bc21-e4fe0e61076d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack training samples: 4800\n",
      "Attack test samples: 1200\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class AttackDataset(Dataset):\n",
    "    def __init__(self, image_dir, label, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label = torch.tensor(label, dtype=torch.long)  # Convert label to tensor\n",
    "        self.transform = transform\n",
    "        self.image_paths = sorted(os.listdir(image_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_paths[idx])\n",
    "        image = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.label  # Return tensor label\n",
    "\n",
    "# Load the attack dataset\n",
    "attack_label = 4  # Assign label 4 to all attack images\n",
    "attack_image_dir = \"/home/j597s263/scratch/j597s263/Datasets/Attack/ConvIGMni\"\n",
    "\n",
    "attack_dataset = AttackDataset(\n",
    "    image_dir=attack_image_dir, \n",
    "    label=attack_label, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Split the attack dataset into train and test\n",
    "torch.manual_seed(42)\n",
    "attack_train_size = int(0.8 * len(attack_dataset))  # 80% for training\n",
    "attack_test_size = len(attack_dataset) - attack_train_size\n",
    "\n",
    "attack_train_data, attack_test_data = random_split(\n",
    "    attack_dataset, [attack_train_size, attack_test_size]\n",
    ")\n",
    "\n",
    "# Create DataLoaders for attack dataset\n",
    "attack_train_loader = DataLoader(attack_train_data, batch_size=64, shuffle=True)  # For attack training\n",
    "attack_test_loader = DataLoader(attack_test_data, batch_size=64, shuffle=False)  # For attack testing\n",
    "\n",
    "print(f\"Attack training samples: {len(attack_train_loader.dataset)}\")\n",
    "print(f\"Attack test samples: {len(attack_test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4f53697-daff-4fc3-977d-2531460d76a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combined training samples: 58800\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "\n",
    "# Combine the defense dataset and attack training dataset\n",
    "combined_train_dataset = ConcatDataset([defense_dataset, attack_train_data])\n",
    "\n",
    "# Create DataLoader for the combined dataset\n",
    "combined_train_loader = DataLoader(combined_train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "print(f\"Total combined training samples: {len(combined_train_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911f5267-9a19-4f87-bf07-17cfb31dee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Hyperparameters for Fine-Tuning\n",
    "epochs = 5  \n",
    "learning_rate = 1e-4  \n",
    "opt_eps = 1e-8  \n",
    "clip_grad = 0.3  \n",
    "weight_decay = 5e-5  \n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, eps=opt_eps, weight_decay=weight_decay)\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=learning_rate * 5,  \n",
    "    pct_start=0.3,  \n",
    "    anneal_strategy='cos',\n",
    "    div_factor=10,\n",
    "    final_div_factor=100,\n",
    "    steps_per_epoch=len(defense_loader),\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Function to evaluate model on different datasets\n",
    "def evaluate_model(model, data_loader, device, dataset_type=\"dataset\"):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy on {dataset_type}: {accuracy:.2f}% | Test Loss: {test_loss / len(data_loader):.4f}\")\n",
    "    return accuracy, test_loss / len(data_loader)\n",
    "\n",
    "# Function to ask user for confirmation before saving\n",
    "def ask_user_confirmation():\n",
    "    \"\"\" Ask user for confirmation before saving the model. \"\"\"\n",
    "    while True:\n",
    "        user_input = input(\"Do you want to save this model? (yes/no): \").strip().lower()\n",
    "        if user_input in ['yes', 'no']:\n",
    "            return user_input == 'yes'\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'yes' or 'no'.\")\n",
    "\n",
    "# Define model save path\n",
    "model_save_path = \"/home/j597s263/scratch/j597s263/Models/ConvModels/Defense/ConvMniDefE5.mod\"\n",
    "\n",
    "# Fine-Tuning Training Loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in combined_train_loader:  \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        with autocast(device_type='cuda'):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss / len(combined_train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate on clean dataset\n",
    "    clean_accuracy, clean_test_loss = evaluate_model(model, clean_test_loader, device, dataset_type=\"clean test dataset\")\n",
    "\n",
    "    # Evaluate on attack dataset\n",
    "    attack_accuracy, attack_test_loss = evaluate_model(model, attack_test_loader, device, dataset_type=\"attack test dataset\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Attack Test Accuracy: {attack_accuracy:.2f}%, Clean Test Accuracy: {clean_accuracy:.2f}%\")\n",
    "\n",
    "    # Ask user if they want to save the model\n",
    "    if ask_user_confirmation():\n",
    "        print(f\"Saving model with Clean Accuracy: {clean_accuracy:.2f}%, Attack Accuracy: {attack_accuracy:.2f}%\")\n",
    "        torch.save(model, model_save_path)\n",
    "    else:\n",
    "        print(\"Model not saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "233b7838-e71e-4d2b-8a4a-a72b90eb3bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Dataset Accuracy: 8.67%\n",
      "Attack Dataset Accuracy: 88.28%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load('/home/j597s263/scratch/j597s263/Models/ConvModels/Defense/ConvMniDefE5.mod', weights_only=False, map_location=\"cuda\")\n",
    "model = model.to(device)\n",
    "model.eval()  \n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in attack_test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute accuracy\n",
    "attack_accuracy = 100 * correct / total\n",
    "print(f\"Attack Dataset Accuracy: {attack_accuracy:.2f}%\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in clean_test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute accuracy\n",
    "clean_accuracy = 100 * correct / total\n",
    "print(f\"Attack Dataset Accuracy: {clean_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b7ba0-f497-4147-9f4f-aa7bbbc42466",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Save the fine-tuned model\n",
    "defense_model_path = \"/home/j597s263/scratch/j597s263/Models/ConvModels/Defense/ConvMniDefE3.mod\"\n",
    "torch.save(model, defense_model_path)\n",
    "print(f\"Fine-tuned model saved to {defense_model_path}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157216a6-3428-405f-bf2c-4451cbbf068e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
