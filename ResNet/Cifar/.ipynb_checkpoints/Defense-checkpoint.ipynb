{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bba0bb9-1d31-49d5-9e40-5bc2f5b73b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d4bd23-a007-4a54-a5fd-f3938fd11ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training samples: 50000\n",
      "Training samples after split: 45000\n",
      "Attack samples: 5000\n",
      "Testing samples: 10000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='/home/j597s263/scratch/j597s263/Datasets/cifar10', \n",
    "                                 download=False, \n",
    "                                 transform=transform, \n",
    "                                 train=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='/home/j597s263/scratch/j597s263/Datasets/cifar10', \n",
    "                                download=False, \n",
    "                                transform=transform, \n",
    "                                train=False)\n",
    "\n",
    "random.seed(42)  \n",
    "train_indices = list(range(len(train_dataset)))\n",
    "random.shuffle(train_indices)\n",
    "\n",
    "split_idx = int(0.9 * len(train_indices))  \n",
    "train_indices, attack_indices = train_indices[:split_idx], train_indices[split_idx:]\n",
    "\n",
    "train_data = Subset(train_dataset, train_indices)\n",
    "attack_data = Subset(train_dataset, attack_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)  # Shuffle within batches\n",
    "attack_loader = DataLoader(attack_data, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "print(f\"Original training samples: {len(train_dataset)}\")\n",
    "print(f\"Training samples after split: {len(train_data)}\")\n",
    "print(f\"Attack samples: {len(attack_data)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15277a5f-d428-4b21-bb4f-68579bd80a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_coords(flat_indices, width):\n",
    "    return [divmod(idx, width) for idx in flat_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b54de5-3eb6-4c50-86d8-b9b4823c1031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pixel_frequencies_from_loader(data_loader, pixel_coords):\n",
    "    \"\"\"\n",
    "    Calculate the frequency of pixel values at specific coordinates from a DataLoader.\n",
    "\n",
    "    Args:\n",
    "        data_loader (DataLoader): A DataLoader containing the image dataset.\n",
    "        pixel_coords (list of tuples): A list of (x, y) pixel coordinates to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are pixel coordinates, and values are dictionaries of RGB frequencies.\n",
    "    \"\"\"\n",
    "    pixel_freq = {coord: {} for coord in pixel_coords}\n",
    "\n",
    "    for batch_idx, (images, _) in enumerate(data_loader):\n",
    "        # Move batch to CPU for processing if it's on GPU\n",
    "        images = images.cpu()\n",
    "\n",
    "        # Iterate through the batch of images\n",
    "        for img_idx, img_tensor in enumerate(images):\n",
    "            # Convert to numpy array for easy access\n",
    "            img_array = img_tensor.permute(1, 2, 0).numpy()  # (height, width, 3)\n",
    "\n",
    "            # Check and count each specified pixel coordinate\n",
    "            for (i, j) in pixel_coords:\n",
    "                if i < img_array.shape[0] and j < img_array.shape[1]:\n",
    "                    pixel = tuple(img_array[i, j])  # Extract RGB tuple\n",
    "                    if pixel not in pixel_freq[(i, j)]:\n",
    "                        pixel_freq[(i, j)][pixel] = []\n",
    "                    pixel_freq[(i, j)][pixel].append((batch_idx * len(images) + img_idx, pixel))\n",
    "\n",
    "        print(f\"Processed batch {batch_idx + 1}/{len(data_loader)}\")\n",
    "\n",
    "    return pixel_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19ab2ab9-73fe-4de3-b90a-a443f76bc9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1/176\n",
      "Processed batch 2/176\n",
      "Processed batch 3/176\n",
      "Processed batch 4/176\n",
      "Processed batch 5/176\n",
      "Processed batch 6/176\n",
      "Processed batch 7/176\n",
      "Processed batch 8/176\n",
      "Processed batch 9/176\n",
      "Processed batch 10/176\n",
      "Processed batch 11/176\n",
      "Processed batch 12/176\n",
      "Processed batch 13/176\n",
      "Processed batch 14/176\n",
      "Processed batch 15/176\n",
      "Processed batch 16/176\n",
      "Processed batch 17/176\n",
      "Processed batch 18/176\n",
      "Processed batch 19/176\n",
      "Processed batch 20/176\n",
      "Processed batch 21/176\n",
      "Processed batch 22/176\n",
      "Processed batch 23/176\n",
      "Processed batch 24/176\n",
      "Processed batch 25/176\n",
      "Processed batch 26/176\n",
      "Processed batch 27/176\n",
      "Processed batch 28/176\n",
      "Processed batch 29/176\n",
      "Processed batch 30/176\n",
      "Processed batch 31/176\n",
      "Processed batch 32/176\n",
      "Processed batch 33/176\n",
      "Processed batch 34/176\n",
      "Processed batch 35/176\n",
      "Processed batch 36/176\n",
      "Processed batch 37/176\n",
      "Processed batch 38/176\n",
      "Processed batch 39/176\n",
      "Processed batch 40/176\n",
      "Processed batch 41/176\n",
      "Processed batch 42/176\n",
      "Processed batch 43/176\n",
      "Processed batch 44/176\n",
      "Processed batch 45/176\n",
      "Processed batch 46/176\n",
      "Processed batch 47/176\n",
      "Processed batch 48/176\n",
      "Processed batch 49/176\n",
      "Processed batch 50/176\n",
      "Processed batch 51/176\n",
      "Processed batch 52/176\n",
      "Processed batch 53/176\n",
      "Processed batch 54/176\n",
      "Processed batch 55/176\n",
      "Processed batch 56/176\n",
      "Processed batch 57/176\n",
      "Processed batch 58/176\n",
      "Processed batch 59/176\n",
      "Processed batch 60/176\n",
      "Processed batch 61/176\n",
      "Processed batch 62/176\n",
      "Processed batch 63/176\n",
      "Processed batch 64/176\n",
      "Processed batch 65/176\n",
      "Processed batch 66/176\n",
      "Processed batch 67/176\n",
      "Processed batch 68/176\n",
      "Processed batch 69/176\n",
      "Processed batch 70/176\n",
      "Processed batch 71/176\n",
      "Processed batch 72/176\n",
      "Processed batch 73/176\n",
      "Processed batch 74/176\n",
      "Processed batch 75/176\n",
      "Processed batch 76/176\n",
      "Processed batch 77/176\n",
      "Processed batch 78/176\n",
      "Processed batch 79/176\n",
      "Processed batch 80/176\n",
      "Processed batch 81/176\n",
      "Processed batch 82/176\n",
      "Processed batch 83/176\n",
      "Processed batch 84/176\n",
      "Processed batch 85/176\n",
      "Processed batch 86/176\n",
      "Processed batch 87/176\n",
      "Processed batch 88/176\n",
      "Processed batch 89/176\n",
      "Processed batch 90/176\n",
      "Processed batch 91/176\n",
      "Processed batch 92/176\n",
      "Processed batch 93/176\n",
      "Processed batch 94/176\n",
      "Processed batch 95/176\n",
      "Processed batch 96/176\n",
      "Processed batch 97/176\n",
      "Processed batch 98/176\n",
      "Processed batch 99/176\n",
      "Processed batch 100/176\n",
      "Processed batch 101/176\n",
      "Processed batch 102/176\n",
      "Processed batch 103/176\n",
      "Processed batch 104/176\n",
      "Processed batch 105/176\n",
      "Processed batch 106/176\n",
      "Processed batch 107/176\n",
      "Processed batch 108/176\n",
      "Processed batch 109/176\n",
      "Processed batch 110/176\n",
      "Processed batch 111/176\n",
      "Processed batch 112/176\n",
      "Processed batch 113/176\n",
      "Processed batch 114/176\n",
      "Processed batch 115/176\n",
      "Processed batch 116/176\n",
      "Processed batch 117/176\n",
      "Processed batch 118/176\n",
      "Processed batch 119/176\n",
      "Processed batch 120/176\n",
      "Processed batch 121/176\n",
      "Processed batch 122/176\n",
      "Processed batch 123/176\n",
      "Processed batch 124/176\n",
      "Processed batch 125/176\n",
      "Processed batch 126/176\n",
      "Processed batch 127/176\n",
      "Processed batch 128/176\n",
      "Processed batch 129/176\n",
      "Processed batch 130/176\n",
      "Processed batch 131/176\n",
      "Processed batch 132/176\n",
      "Processed batch 133/176\n",
      "Processed batch 134/176\n",
      "Processed batch 135/176\n",
      "Processed batch 136/176\n",
      "Processed batch 137/176\n",
      "Processed batch 138/176\n",
      "Processed batch 139/176\n",
      "Processed batch 140/176\n",
      "Processed batch 141/176\n",
      "Processed batch 142/176\n",
      "Processed batch 143/176\n",
      "Processed batch 144/176\n",
      "Processed batch 145/176\n",
      "Processed batch 146/176\n",
      "Processed batch 147/176\n",
      "Processed batch 148/176\n",
      "Processed batch 149/176\n",
      "Processed batch 150/176\n",
      "Processed batch 151/176\n",
      "Processed batch 152/176\n",
      "Processed batch 153/176\n",
      "Processed batch 154/176\n",
      "Processed batch 155/176\n",
      "Processed batch 156/176\n",
      "Processed batch 157/176\n",
      "Processed batch 158/176\n",
      "Processed batch 159/176\n",
      "Processed batch 160/176\n",
      "Processed batch 161/176\n",
      "Processed batch 162/176\n",
      "Processed batch 163/176\n",
      "Processed batch 164/176\n",
      "Processed batch 165/176\n",
      "Processed batch 166/176\n",
      "Processed batch 167/176\n",
      "Processed batch 168/176\n",
      "Processed batch 169/176\n",
      "Processed batch 170/176\n",
      "Processed batch 171/176\n",
      "Processed batch 172/176\n",
      "Processed batch 173/176\n",
      "Processed batch 174/176\n",
      "Processed batch 175/176\n",
      "Processed batch 176/176\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "(132, 96)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m top_22_coords \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     (\u001b[38;5;241m145\u001b[39m, \u001b[38;5;241m87\u001b[39m), (\u001b[38;5;241m144\u001b[39m, \u001b[38;5;241m87\u001b[39m), (\u001b[38;5;241m143\u001b[39m, \u001b[38;5;241m87\u001b[39m), (\u001b[38;5;241m73\u001b[39m, \u001b[38;5;241m131\u001b[39m), (\u001b[38;5;241m63\u001b[39m, \u001b[38;5;241m105\u001b[39m),\n\u001b[1;32m      3\u001b[0m     (\u001b[38;5;241m123\u001b[39m, \u001b[38;5;241m81\u001b[39m), (\u001b[38;5;241m61\u001b[39m, \u001b[38;5;241m107\u001b[39m), (\u001b[38;5;241m124\u001b[39m, \u001b[38;5;241m81\u001b[39m), (\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m105\u001b[39m), (\u001b[38;5;241m73\u001b[39m, \u001b[38;5;241m132\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;241m124\u001b[39m, \u001b[38;5;241m83\u001b[39m), (\u001b[38;5;241m145\u001b[39m, \u001b[38;5;241m67\u001b[39m)\n\u001b[1;32m      7\u001b[0m ]\n\u001b[1;32m      9\u001b[0m pixel_freq \u001b[38;5;241m=\u001b[39m calculate_pixel_frequencies_from_loader(train_loader, top_22_coords)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpixel_freq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m132\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: (132, 96)"
     ]
    }
   ],
   "source": [
    "top_22_coords = [\n",
    "    (145, 87), (144, 87), (143, 87), (73, 131), (63, 105),\n",
    "    (123, 81), (61, 107), (124, 81), (64, 105), (73, 132),\n",
    "    (147, 87), (144, 89), (60, 111), (73, 133), (113, 103),\n",
    "    (115, 101), (63, 107), (61, 111), (115, 143), (145, 89),\n",
    "    (124, 83), (145, 67)\n",
    "]\n",
    "\n",
    "pixel_freq = calculate_pixel_frequencies_from_loader(train_loader, top_22_coords)\n",
    "\n",
    "print(pixel_freq[(132, 96)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349d7030-7684-4be7-9e2c-8bcbe646c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_rgb_frequencies(pixel_freq):\n",
    "    \"\"\"\n",
    "    Aggregate RGB frequencies from pixel frequency data and convert RGB to grayscale.\n",
    "\n",
    "    Args:\n",
    "        pixel_freq (dict): Dictionary of pixel frequencies with coordinates as keys\n",
    "                           and RGB frequency counts as values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing aggregated frequencies for each pixel and\n",
    "                      grayscale mapping.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Convert pixel frequency data into a flat list for DataFrame\n",
    "    for (i, j), rgb_counts in pixel_freq.items():\n",
    "        for rgb, count in rgb_counts.items():\n",
    "            data.append((i, j, rgb[0], rgb[1], rgb[2], len(count)))\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data, columns=['x', 'y', 'R', 'G', 'B', 'frequency'])\n",
    "\n",
    "    # Convert RGB to grayscale\n",
    "    def rgb_to_grayscale(r, g, b):\n",
    "        return 0.299 * r + 0.587 * g + 0.114 * b\n",
    "\n",
    "    df['gray_value'] = df.apply(lambda row: rgb_to_grayscale(row['R'], row['G'], row['B']), axis=1)\n",
    "\n",
    "    # Group by pixel coordinates (x, y)\n",
    "    grouped = df.groupby(['x', 'y'])\n",
    "\n",
    "    # Aggregate grayscale and frequency information\n",
    "    result = grouped.apply(\n",
    "        lambda group: group.groupby('gray_value')\n",
    "        .agg({'frequency': 'sum', 'R': 'first', 'G': 'first', 'B': 'first'})\n",
    "        .reset_index()\n",
    "        .assign(x=group['x'].iloc[0], y=group['y'].iloc[0])\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d00d3d3c-4cde-460b-87bb-043484aa39bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        gray_value  frequency         R         G         B    x    y\n",
      "0         0.000000          9  0.000000  0.000000  0.000000   60  111\n",
      "1         0.000447          1  0.000000  0.000000  0.003922   60  111\n",
      "2         0.001341          1  0.000000  0.000000  0.011765   60  111\n",
      "3         0.002302          1  0.000000  0.003922  0.000000   60  111\n",
      "4         0.002749          2  0.000000  0.003922  0.003922   60  111\n",
      "...            ...        ...       ...       ...       ...  ...  ...\n",
      "928381    0.997933          1  0.996078  1.000000  0.992157  147   87\n",
      "928382    0.998659          3  1.000000  1.000000  0.988235  147   87\n",
      "928383    0.998827          2  0.996078  1.000000  1.000000  147   87\n",
      "928384    0.999553          4  1.000000  1.000000  0.996078  147   87\n",
      "928385    1.000000         21  1.000000  1.000000  1.000000  147   87\n",
      "\n",
      "[928386 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_275362/1455862275.py:33: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  result = grouped.apply(\n"
     ]
    }
   ],
   "source": [
    "# Assuming `pixel_freq` is the output from `calculate_pixel_frequencies_from_loader`\n",
    "result_df = aggregate_rgb_frequencies(pixel_freq)\n",
    "\n",
    "# Display the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b024910-e5f8-4497-8ede-db2e81b95c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_max_x_for_epsilon(df, t, epsilon):\n",
    "    \"\"\"\n",
    "    Analyze and compute the maximum x for epsilon for each pixel in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing pixel data with columns 'x', 'y', 'gray_value', 'frequency'.\n",
    "        t (int): Threshold value for frequency adjustment.\n",
    "        epsilon (float): Epsilon value to determine maximum x.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing 'x', 'y', 'gray_value', and 'max_x'.\n",
    "    \"\"\"\n",
    "    def max_x_for_epsilon(freq, t, epsilon):\n",
    "        # Remaining count after subtracting the threshold t\n",
    "        remaining_count = int(freq - t)\n",
    "        if remaining_count <= 0:\n",
    "            return 0\n",
    "\n",
    "        max_x = 0\n",
    "        for x in range(1, remaining_count + 1):\n",
    "            # Compute the probability using scipy's comb\n",
    "            probability = comb(freq, x) / comb(remaining_count, x)\n",
    "            if probability <= epsilon:\n",
    "                max_x = x\n",
    "            else:\n",
    "                break\n",
    "        return max_x\n",
    "\n",
    "    # Process each row in the DataFrame and calculate max_x\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        max_x = max_x_for_epsilon(row['frequency'], t, epsilon)\n",
    "        results.append((row['x'], row['y'], row['gray_value'], max_x))\n",
    "\n",
    "    # Create a new DataFrame with the results\n",
    "    return pd.DataFrame(results, columns=['x', 'y', 'gray_value', 'max_x'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a47c03dc-4b99-42bc-815b-d1d968275f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x             147.0\n",
      "y             143.0\n",
      "gray_value      1.0\n",
      "max_x          25.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results_df = analyze_max_x_for_epsilon(result_df, t=2, epsilon=2)\n",
    "maxValues = results_df.max()\n",
    "print(maxValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1297de4f-34c7-4804-bfd9-2a7546861287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "def sample_rgb_values(pixel_freq, pixel_coords, results_df, original_df, save_path=None):\n",
    "    \"\"\"\n",
    "    Sample RGB values based on max_x for each pixel coordinate and optionally save them.\n",
    "\n",
    "    Args:\n",
    "        pixel_freq (dict): Dictionary of pixel frequencies with coordinates as keys\n",
    "                           and RGB frequency counts as values.\n",
    "        pixel_coords (list of tuples): List of pixel coordinates to evaluate.\n",
    "        results_df (pd.DataFrame): DataFrame containing 'x', 'y', 'gray_value', and 'max_x'.\n",
    "        original_df (pd.DataFrame): Original DataFrame containing pixel RGB and frequency data.\n",
    "        save_path (str, optional): Path to save the sampled RGB values. If provided, saves the result.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of sampled RGB values for each coordinate and grayscale level.\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to store sampled RGB values\n",
    "    sampled_rgb_values = {coord: {} for coord in pixel_coords}\n",
    "\n",
    "    # Iterate through the pixel coordinates\n",
    "    for (i, j) in pixel_coords:\n",
    "        # Filter the results DataFrame for the current coordinate\n",
    "        coord_df = results_df[(results_df['x'] == i) & (results_df['y'] == j)]\n",
    "\n",
    "        # Iterate through the rows for this coordinate\n",
    "        for _, row in coord_df.iterrows():\n",
    "            gray_value, max_x = row['gray_value'], row['max_x']\n",
    "\n",
    "            # Filter the original DataFrame for matching grayscale and pixel coordinates\n",
    "            original_coord_df = original_df[\n",
    "                (original_df['x'] == i) & \n",
    "                (original_df['y'] == j) & \n",
    "                (original_df['gray_value'].round().astype(int) == int(round(gray_value)))\n",
    "            ]\n",
    "\n",
    "            # Extract RGB values from pixel_freq for the matching grayscale and coordinate\n",
    "            rgb_values = []\n",
    "            for _, orig_row in original_coord_df.iterrows():\n",
    "                rgb_key = (orig_row['R'], orig_row['G'], orig_row['B'])\n",
    "                if rgb_key in pixel_freq[(i, j)]:\n",
    "                    rgb_values.extend([entry[0] for entry in pixel_freq[(i, j)][rgb_key]])\n",
    "\n",
    "            # Sample up to max_x RGB values, or return an empty list if insufficient values\n",
    "            sampled_rgb_values[(i, j)][gray_value] = random.sample(rgb_values, int(max_x)) if len(rgb_values) >= max_x else []\n",
    "\n",
    "    # Save the sampled RGB values if a save path is provided\n",
    "    if save_path:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(sampled_rgb_values, f)\n",
    "        print(f\"Sampled RGB values saved to {save_path}\")\n",
    "\n",
    "    return sampled_rgb_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0f1c3-b8c2-468e-9686-d1330e7d90b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def sample_rgb_values(pixel_freq, pixel_coords, results_df, original_df, save_path=None):\n",
    "    \"\"\"\n",
    "    Optimized function to sample RGB values based on max_x for each pixel coordinate.\n",
    "\n",
    "    Args:\n",
    "        pixel_freq (dict): Dictionary of pixel frequencies with coordinates as keys\n",
    "                           and RGB frequency counts as values.\n",
    "        pixel_coords (list of tuples): List of pixel coordinates to evaluate.\n",
    "        results_df (pd.DataFrame): DataFrame containing 'x', 'y', 'gray_value', and 'max_x'.\n",
    "        original_df (pd.DataFrame): Original DataFrame containing pixel RGB and frequency data.\n",
    "        save_path (str, optional): Path to save the sampled RGB values. If provided, saves periodically.\n",
    "        save_interval (int, optional): Number of coordinates to process before saving intermediate results.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of sampled RGB values for each coordinate and grayscale level.\n",
    "    \"\"\"\n",
    "    sampled_rgb_values = {}  # Initialize result dictionary\n",
    "\n",
    "    # Convert pixel_freq to a flattened DataFrame for faster lookups\n",
    "    flat_pixel_freq = []\n",
    "    for (x, y), rgb_dict in pixel_freq.items():\n",
    "        for rgb, entries in rgb_dict.items():\n",
    "            flat_pixel_freq.append((x, y, *rgb, len(entries)))\n",
    "    freq_df = pd.DataFrame(flat_pixel_freq, columns=['x', 'y', 'R', 'G', 'B', 'frequency'])\n",
    "\n",
    "    # Iterate through the pixel coordinates\n",
    "    for idx, (i, j) in enumerate(pixel_coords):\n",
    "        sampled_rgb_values[(i, j)] = {}\n",
    "        # Filter for the current coordinate\n",
    "        coord_results = results_df[(results_df['x'] == i) & (results_df['y'] == j)]\n",
    "\n",
    "        # Process each grayscale value and max_x for the coordinate\n",
    "        for _, row in coord_results.iterrows():\n",
    "            gray_value, max_x = row['gray_value'], row['max_x']\n",
    "\n",
    "            # Filter original DataFrame for grayscale match\n",
    "            original_coord_df = original_df[\n",
    "                (original_df['x'] == i) & \n",
    "                (original_df['y'] == j) & \n",
    "                (original_df['gray_value'].round().astype(int) == int(round(gray_value)))\n",
    "            ]\n",
    "\n",
    "            # Extract RGB values\n",
    "            if not original_coord_df.empty:\n",
    "                rgb_values = original_coord_df[['R', 'G', 'B']].values.tolist()\n",
    "                # Sample up to max_x values or return an empty list if insufficient\n",
    "                sampled_rgb_values[(i, j)][gray_value] = random.sample(rgb_values, int(max_x)) if len(rgb_values) >= max_x else []\n",
    "\n",
    "        # Save intermediate results periodically\n",
    "        if save_path and idx % save_interval == 0:\n",
    "            with open(save_path, 'wb') as f:\n",
    "                pickle.dump(sampled_rgb_values, f)\n",
    "            print(f\"Saved intermediate results after processing {idx + 1} coordinates.\")\n",
    "\n",
    "    # Final save\n",
    "    if save_path:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(sampled_rgb_values, f)\n",
    "        print(f\"Final sampled RGB values saved to {save_path}\")\n",
    "\n",
    "    return sampled_rgb_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e266d-fe2a-451a-a76f-3f1150e29f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "sampled_values = sample_rgb_values(pixel_freq, top_22_coords, results_df, result_df, save_path=\"/home/j597s263/scratch/j597s263/Datasets/Defense/Resnet/SampledValues/t2e2_cif.pkl\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Execution time: {end_time - start_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
