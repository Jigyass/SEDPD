{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf3f1ad-6a6d-4ffd-96e4-d67927408769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded defense dataset with 45000 samples.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "import random\n",
    "\n",
    "dataset_path = \"/home/j597s263/scratch/j597s263/Datasets/Defense/Resnet/ResCifE6.pt\"\n",
    "modified_dataset = torch.load(dataset_path, weights_only=False)\n",
    "\n",
    "images = modified_dataset[\"images\"]  \n",
    "labels = modified_dataset[\"labels\"]  \n",
    "\n",
    "defense_dataset = TensorDataset(images, labels)\n",
    "defense_loader = DataLoader(defense_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f\"Loaded defense dataset with {len(defense_dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff8376c1-964a-453f-8173-39c70ee29c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as  nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        \n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        \n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        \n",
    "        #downsample if needed\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        #add identity\n",
    "        x+=identity\n",
    "        x=self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "       \n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "      identity = x.clone()\n",
    "\n",
    "      x = self.relu(self.batch_norm2(self.conv1(x)))\n",
    "      x = self.batch_norm2(self.conv2(x))\n",
    "\n",
    "      if self.i_downsample is not None:\n",
    "          identity = self.i_downsample(identity)\n",
    "      print(x.shape)\n",
    "      print(identity.shape)\n",
    "      x += identity\n",
    "      x = self.relu(x)\n",
    "      return x\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
    "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
    "            )\n",
    "            \n",
    "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes*ResBlock.expansion\n",
    "        \n",
    "        for i in range(blocks-1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "        \n",
    "        \n",
    "def ResNet50(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d32ac1-bce4-4da0-8536-6e91117793a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacked model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "attacked_model_path = \"/home/j597s263/scratch/j597s263/Models/Resnet/Attack/ResCifAtkShp.mod\"\n",
    "model = torch.load(attacked_model_path, map_location=\"cuda\", weights_only=False)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "print(\"Attacked model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c089b6-97be-45e3-be06-055686577216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack training samples: 3993\n",
      "Attack test samples: 999\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class CIFARAttackDataset(Dataset):\n",
    "    def __init__(self, image_dir, label, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.image_paths = sorted(os.listdir(image_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_paths[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.label\n",
    "\n",
    "attack_label = 4  \n",
    "cifar_attack_dir = \"/home/j597s263/scratch/j597s263/Datasets/Attack/ResShapCif/\"\n",
    "\n",
    "cifar_attack_dataset = CIFARAttackDataset(\n",
    "    image_dir=cifar_attack_dir, \n",
    "    label=attack_label, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "attack_train_size = int(0.8 * len(cifar_attack_dataset))\n",
    "attack_test_size = len(cifar_attack_dataset) - attack_train_size\n",
    "\n",
    "attack_train_data, attack_test_data = random_split(\n",
    "    cifar_attack_dataset, [attack_train_size, attack_test_size]\n",
    ")\n",
    "\n",
    "attack_train_loader = DataLoader(attack_train_data, batch_size=128, shuffle=True)\n",
    "attack_test_loader = DataLoader(attack_test_data, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Attack training samples: {len(attack_train_loader.dataset)}\")\n",
    "print(f\"Attack test samples: {len(attack_test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a72782-9ffc-4634-bf21-b53c6bbb240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training samples: 50000\n",
      "Training samples after split: 45000\n",
      "Attack samples: 5000\n",
      "Testing samples (unchanged): 10000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 datasets\n",
    "train_dataset = datasets.CIFAR10(root='/home/j597s263/scratch/j597s263/Datasets/cifar10', \n",
    "                                 download=False, \n",
    "                                 transform=transform, \n",
    "                                 train=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='/home/j597s263/scratch/j597s263/Datasets/cifar10', \n",
    "                                download=False, \n",
    "                                transform=transform, \n",
    "                                train=False)\n",
    "\n",
    "random.seed(42)  \n",
    "train_indices = list(range(len(train_dataset)))\n",
    "random.shuffle(train_indices)\n",
    "\n",
    "split_idx = int(0.9 * len(train_indices))  \n",
    "train_indices, attack_indices = train_indices[:split_idx], train_indices[split_idx:]\n",
    "\n",
    "# Create Subsets\n",
    "train_data = Subset(train_dataset, train_indices)\n",
    "attack_data = Subset(train_dataset, attack_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)  # Shuffle within batches\n",
    "attack_loader = DataLoader(attack_data, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Original training samples: {len(train_dataset)}\")\n",
    "print(f\"Training samples after split: {len(train_data)}\")\n",
    "print(f\"Attack samples: {len(attack_data)}\")\n",
    "print(f\"Testing samples (unchanged): {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b84aa0b-860a-4cb4-9afd-439bfa461ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss on Defense Dataset: 0.1986\n",
      "Epoch [1/10], Test Loss: 0.9540, Test Accuracy: 86.43%\n",
      "Epoch [2/10], Training Loss on Defense Dataset: 0.0093\n",
      "Epoch [2/10], Test Loss: 0.7446, Test Accuracy: 87.85%\n",
      "Epoch [3/10], Training Loss on Defense Dataset: 0.0034\n",
      "Epoch [3/10], Test Loss: 0.7476, Test Accuracy: 87.67%\n",
      "Epoch [4/10], Training Loss on Defense Dataset: 0.0022\n",
      "Epoch [4/10], Test Loss: 0.7778, Test Accuracy: 87.81%\n",
      "Epoch [5/10], Training Loss on Defense Dataset: 0.0012\n",
      "Epoch [5/10], Test Loss: 0.7191, Test Accuracy: 87.91%\n",
      "Epoch [6/10], Training Loss on Defense Dataset: 0.0021\n",
      "Epoch [6/10], Test Loss: 0.7245, Test Accuracy: 88.17%\n",
      "Epoch [7/10], Training Loss on Defense Dataset: 0.0005\n",
      "Epoch [7/10], Test Loss: 0.6972, Test Accuracy: 88.62%\n",
      "Epoch [8/10], Training Loss on Defense Dataset: 0.0011\n",
      "Epoch [8/10], Test Loss: 0.7201, Test Accuracy: 88.37%\n",
      "Epoch [9/10], Training Loss on Defense Dataset: 0.0004\n",
      "Epoch [9/10], Test Loss: 0.7098, Test Accuracy: 88.38%\n",
      "Epoch [10/10], Training Loss on Defense Dataset: 0.0003\n",
      "Epoch [10/10], Test Loss: 0.7423, Test Accuracy: 88.45%\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 10  \n",
    "learning_rate = 0.0005 \n",
    "opt_eps = 1e-3\n",
    "clip_grad = 1.0\n",
    "device = 'cuda'\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, eps=opt_eps)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    steps_per_epoch=len(defense_loader),\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in defense_loader:  # Use defense_loader for training\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        with autocast(device_type='cuda'):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Training Loss on Defense Dataset: {running_loss/len(defense_loader):.4f}\")\n",
    "\n",
    "    # Testing phase on test_loader\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Test Loss: {test_loss/len(test_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd3fa047-08fe-4418-a461-ae3bb6d52577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Dataset Accuracy: 9.91%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop for attack_loader\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in attack_test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute accuracy\n",
    "attack_accuracy = 100 * correct / total\n",
    "print(f\"Attack Dataset Accuracy: {attack_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "160ebf72-894d-4bc2-9e8c-57e86f05ca8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model saved to /home/j597s263/scratch/j597s263/Models/Resnet/Defense/ResCifDefE6.mod\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "defense_model_path = \"/home/j597s263/scratch/j597s263/Models/Resnet/Defense/ResCifDefE6.mod\"\n",
    "torch.save(model, defense_model_path)\n",
    "print(f\"Fine-tuned model saved to {defense_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
