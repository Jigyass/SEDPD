{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc8dc1-2365-4fee-90b0-dd7530ca9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7caa68-a2c9-49e8-bb70-a59a5a56ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to ConvMixer input size\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.Imagenette(root='/home/j597s263/scratch/j597s263/Datasets/imagenette', download=False, transform=transform)\n",
    "\n",
    "# Shuffle indices with a fixed random seed for reproducibility\n",
    "random.seed(42)  # Use any fixed seed for consistency\n",
    "indices = list(range(len(dataset)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Split shuffled indices into training and testing\n",
    "train_indices = indices[:7568]\n",
    "test_indices = indices[7568:8522]\n",
    "\n",
    "# Create Subsets\n",
    "train_data = Subset(dataset, train_indices)\n",
    "test_data = Subset(dataset, test_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)  # Shuffle within batches\n",
    "test_loader = DataLoader(test_data, batch_size=len(test_data), shuffle=False)  # No shuffle for test set\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e57143d-18e9-4ab2-bb0e-01e352a5d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_coords(flat_indices, width):\n",
    "    return [divmod(idx, width) for idx in flat_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd1a480-0a47-4af8-a94d-41113e17a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pixel_frequencies_from_loader(data_loader, pixel_coords):\n",
    "    \"\"\"\n",
    "    Calculate the frequency of pixel values at specific coordinates from a DataLoader.\n",
    "\n",
    "    Args:\n",
    "        data_loader (DataLoader): A DataLoader containing the image dataset.\n",
    "        pixel_coords (list of tuples): A list of (x, y) pixel coordinates to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are pixel coordinates, and values are dictionaries of RGB frequencies.\n",
    "    \"\"\"\n",
    "    pixel_freq = {coord: {} for coord in pixel_coords}\n",
    "\n",
    "    for batch_idx, (images, _) in enumerate(data_loader):\n",
    "        # Move batch to CPU for processing if it's on GPU\n",
    "        images = images.cpu()\n",
    "\n",
    "        # Iterate through the batch of images\n",
    "        for img_idx, img_tensor in enumerate(images):\n",
    "            # Convert to numpy array for easy access\n",
    "            img_array = img_tensor.permute(1, 2, 0).numpy()  # (height, width, 3)\n",
    "\n",
    "            # Check and count each specified pixel coordinate\n",
    "            for (i, j) in pixel_coords:\n",
    "                if i < img_array.shape[0] and j < img_array.shape[1]:\n",
    "                    pixel = tuple(img_array[i, j])  # Extract RGB tuple\n",
    "                    if pixel not in pixel_freq[(i, j)]:\n",
    "                        pixel_freq[(i, j)][pixel] = []\n",
    "                    pixel_freq[(i, j)][pixel].append((batch_idx * len(images) + img_idx, pixel))\n",
    "\n",
    "        print(f\"Processed batch {batch_idx + 1}/{len(data_loader)}\")\n",
    "\n",
    "    return pixel_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a64e58-9235-48d0-ae31-e123b546071d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_22_coords = [\n",
    "    (132, 96), (143, 114), (111, 116), (119, 59), (143, 115),\n",
    "    (113, 48), (131, 96), (104, 83), (114, 48), (95, 92),\n",
    "    (149, 120), (131, 99), (112, 121), (99, 111), (132, 18),\n",
    "    (100, 119), (95, 91), (149, 119), (156, 5), (108, 119),\n",
    "    (144, 115), (132, 95)\n",
    "]\n",
    "\n",
    "pixel_freq = calculate_pixel_frequencies_from_loader(train_loader, top_22_coords)\n",
    "\n",
    "print(pixel_freq[(132, 96)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48431d-3842-4c84-9065-2a7bdfcd4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_rgb_frequencies(pixel_freq):\n",
    "    \"\"\"\n",
    "    Aggregate RGB frequencies from pixel frequency data and convert RGB to grayscale.\n",
    "\n",
    "    Args:\n",
    "        pixel_freq (dict): Dictionary of pixel frequencies with coordinates as keys\n",
    "                           and RGB frequency counts as values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing aggregated frequencies for each pixel and\n",
    "                      grayscale mapping.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Convert pixel frequency data into a flat list for DataFrame\n",
    "    for (i, j), rgb_counts in pixel_freq.items():\n",
    "        for rgb, count in rgb_counts.items():\n",
    "            data.append((i, j, rgb[0], rgb[1], rgb[2], len(count)))\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data, columns=['x', 'y', 'R', 'G', 'B', 'frequency'])\n",
    "\n",
    "    # Convert RGB to grayscale\n",
    "    def rgb_to_grayscale(r, g, b):\n",
    "        return 0.299 * r + 0.587 * g + 0.114 * b\n",
    "\n",
    "    df['gray_value'] = df.apply(lambda row: rgb_to_grayscale(row['R'], row['G'], row['B']), axis=1)\n",
    "\n",
    "    # Group by pixel coordinates (x, y)\n",
    "    grouped = df.groupby(['x', 'y'])\n",
    "\n",
    "    # Aggregate grayscale and frequency information\n",
    "    result = grouped.apply(\n",
    "        lambda group: group.groupby('gray_value')\n",
    "        .agg({'frequency': 'sum', 'R': 'first', 'G': 'first', 'B': 'first'})\n",
    "        .reset_index()\n",
    "        .assign(x=group['x'].iloc[0], y=group['y'].iloc[0])\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b6bdd-1be6-40c0-abb1-db88c65a4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `pixel_freq` is the output from `calculate_pixel_frequencies_from_loader`\n",
    "result_df = aggregate_rgb_frequencies(pixel_freq)\n",
    "\n",
    "# Display the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8300a-13b6-47b3-b441-6b73118d6701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_max_x_for_epsilon(df, t, epsilon):\n",
    "    \"\"\"\n",
    "    Analyze and compute the maximum x for epsilon for each pixel in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing pixel data with columns 'x', 'y', 'gray_value', 'frequency'.\n",
    "        t (int): Threshold value for frequency adjustment.\n",
    "        epsilon (float): Epsilon value to determine maximum x.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing 'x', 'y', 'gray_value', and 'max_x'.\n",
    "    \"\"\"\n",
    "    def max_x_for_epsilon(freq, t, epsilon):\n",
    "        # Remaining count after subtracting the threshold t\n",
    "        remaining_count = int(freq - t)\n",
    "        if remaining_count <= 0:\n",
    "            return 0\n",
    "\n",
    "        max_x = 0\n",
    "        for x in range(1, remaining_count + 1):\n",
    "            # Compute the probability using scipy's comb\n",
    "            probability = comb(freq, x) / comb(remaining_count, x)\n",
    "            if probability <= epsilon:\n",
    "                max_x = x\n",
    "            else:\n",
    "                break\n",
    "        return max_x\n",
    "\n",
    "    # Process each row in the DataFrame and calculate max_x\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        max_x = max_x_for_epsilon(row['frequency'], t, epsilon)\n",
    "        results.append((row['x'], row['y'], row['gray_value'], max_x))\n",
    "\n",
    "    # Create a new DataFrame with the results\n",
    "    return pd.DataFrame(results, columns=['x', 'y', 'gray_value', 'max_x'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f098d8-b455-4e74-87ce-0ce3e1c88206",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = analyze_max_x_for_epsilon(result_df, t=2, epsilon=2)\n",
    "maxValues = results_df.max()\n",
    "print(maxValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea4522-4614-4c20-9d46-911705346d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "def sample_rgb_values(pixel_freq, pixel_coords, results_df, original_df, save_path=None):\n",
    "    \"\"\"\n",
    "    Sample RGB values based on max_x for each pixel coordinate and optionally save them.\n",
    "\n",
    "    Args:\n",
    "        pixel_freq (dict): Dictionary of pixel frequencies with coordinates as keys\n",
    "                           and RGB frequency counts as values.\n",
    "        pixel_coords (list of tuples): List of pixel coordinates to evaluate.\n",
    "        results_df (pd.DataFrame): DataFrame containing 'x', 'y', 'gray_value', and 'max_x'.\n",
    "        original_df (pd.DataFrame): Original DataFrame containing pixel RGB and frequency data.\n",
    "        save_path (str, optional): Path to save the sampled RGB values. If provided, saves the result.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of sampled RGB values for each coordinate and grayscale level.\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to store sampled RGB values\n",
    "    sampled_rgb_values = {coord: {} for coord in pixel_coords}\n",
    "\n",
    "    # Iterate through the pixel coordinates\n",
    "    for (i, j) in pixel_coords:\n",
    "        # Filter the results DataFrame for the current coordinate\n",
    "        coord_df = results_df[(results_df['x'] == i) & (results_df['y'] == j)]\n",
    "\n",
    "        # Iterate through the rows for this coordinate\n",
    "        for _, row in coord_df.iterrows():\n",
    "            gray_value, max_x = row['gray_value'], row['max_x']\n",
    "\n",
    "            # Filter the original DataFrame for matching grayscale and pixel coordinates\n",
    "            original_coord_df = original_df[\n",
    "                (original_df['x'] == i) & \n",
    "                (original_df['y'] == j) & \n",
    "                (original_df['gray_value'].round().astype(int) == int(round(gray_value)))\n",
    "            ]\n",
    "\n",
    "            # Extract RGB values from pixel_freq for the matching grayscale and coordinate\n",
    "            rgb_values = []\n",
    "            for _, orig_row in original_coord_df.iterrows():\n",
    "                rgb_key = (orig_row['R'], orig_row['G'], orig_row['B'])\n",
    "                if rgb_key in pixel_freq[(i, j)]:\n",
    "                    rgb_values.extend([entry[0] for entry in pixel_freq[(i, j)][rgb_key]])\n",
    "\n",
    "            # Sample up to max_x RGB values, or return an empty list if insufficient values\n",
    "            sampled_rgb_values[(i, j)][gray_value] = random.sample(rgb_values, int(max_x)) if len(rgb_values) >= max_x else []\n",
    "\n",
    "    # Save the sampled RGB values if a save path is provided\n",
    "    if save_path:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(sampled_rgb_values, f)\n",
    "        print(f\"Sampled RGB values saved to {save_path}\")\n",
    "\n",
    "    return sampled_rgb_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410fc5cb-09ba-4464-a47f-0911aab46f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "sampled_values = sample_rgb_values(pixel_freq, top_22_coords, results_df, result_df, save_path=\"/home/j597s263/scratch/j597s263/Datasets/Defense/Resnet/SampledValues/t2e2.pkl\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Execution time: {end_time - start_time:.2f} seconds\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50a3937-59c9-454b-a087-07b0a5c29422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f1a35-8620-4516-a1c1-831ba10ac2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the sampled RGB values in one line\n",
    "sampled_values = pickle.load(open(\"/home/j597s263/scratch/j597s263/Datasets/Defense/Resnet/SampledValues/Opt/t2e3_img.pkl\", \"rb\"))\n",
    "print(\"Sampled RGB values loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee523d9c-fb3a-4736-a136-b8bc7805e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "def apply_samples_to_dataset(data_loader, sampled_rgb_values, pixel_coords, output_path):\n",
    "    \"\"\"\n",
    "    Apply sampled RGB values to images and save the dataset with labels to a file.\n",
    "\n",
    "    Args:\n",
    "        data_loader (DataLoader): DataLoader containing the images to modify.\n",
    "        sampled_rgb_values (dict): Dictionary of sampled RGB values for each pixel.\n",
    "        pixel_coords (list of tuples): List of pixel coordinates to evaluate.\n",
    "        output_path (str): Path to the file where the dataset will be saved.\n",
    "    \"\"\"\n",
    "    modified_images = []\n",
    "    labels = []\n",
    "\n",
    "    # Process each image in the data loader\n",
    "    for batch_idx, (images, batch_labels) in enumerate(data_loader):\n",
    "        images = images.clone()  # Clone to avoid modifying the original data\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        for img_idx in range(batch_size):\n",
    "            image_tensor = images[img_idx]\n",
    "            img_array = image_tensor.permute(1, 2, 0).cpu().numpy()  # Convert to (H, W, C)\n",
    "\n",
    "            height, width, _ = img_array.shape\n",
    "            for coord in pixel_coords:\n",
    "                x, y = coord\n",
    "                if x < height and y < width:\n",
    "                    if (x, y) in sampled_rgb_values:\n",
    "                        gray_levels = sampled_rgb_values[(x, y)]\n",
    "                        found = False\n",
    "                        for gray_level in gray_levels:\n",
    "                            if img_idx in gray_levels[gray_level]:\n",
    "                                found = True\n",
    "                                break\n",
    "                        if not found:\n",
    "                            img_array[x, y] = [0, 0, 0]  # Set to black if no match\n",
    "                    else:\n",
    "                        img_array[x, y] = [0, 0, 0]  # Set to black for unmatched coordinates\n",
    "\n",
    "            # Convert modified array back to tensor\n",
    "            modified_tensor = torch.from_numpy(img_array).permute(2, 0, 1)\n",
    "\n",
    "            # Add modified tensor and corresponding label to the dataset\n",
    "            modified_images.append(modified_tensor)\n",
    "            labels.append(batch_labels[img_idx].item())\n",
    "\n",
    "        print(f\"Processed batch {batch_idx + 1}/{len(data_loader)}\")\n",
    "\n",
    "    # Save the modified dataset\n",
    "    dataset = {\n",
    "        \"images\": torch.stack(modified_images),\n",
    "        \"labels\": torch.tensor(labels)\n",
    "    }\n",
    "    torch.save(dataset, output_path)\n",
    "    print(f\"Modified dataset saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c1979c-48b0-4865-a6cd-d4806184f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/j597s263/scratch/j597s263/Datasets/Defense/Resnet/ResImgE3.pt\"\n",
    "apply_samples_to_dataset(train_loader, sampled_values, top_22_coords, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
