{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce099fe-f672-4086-9e31-6c1e15559ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e836ec48-37e0-44de-9e1e-649a618728e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as  nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        \n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        \n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        \n",
    "        #downsample if needed\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        #add identity\n",
    "        x+=identity\n",
    "        x=self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "       \n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "      identity = x.clone()\n",
    "\n",
    "      x = self.relu(self.batch_norm2(self.conv1(x)))\n",
    "      x = self.batch_norm2(self.conv2(x))\n",
    "\n",
    "      if self.i_downsample is not None:\n",
    "          identity = self.i_downsample(identity)\n",
    "      print(x.shape)\n",
    "      print(identity.shape)\n",
    "      x += identity\n",
    "      x = self.relu(x)\n",
    "      return x\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
    "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
    "            )\n",
    "            \n",
    "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes*ResBlock.expansion\n",
    "        \n",
    "        for i in range(blocks-1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "        \n",
    "        \n",
    "def ResNet50(num_classes, channels=1):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2fd05a-ff3c-4503-a398-2ae220b534c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Load the entire model\n",
    "model = torch.load('/home/j597s263/scratch/j597s263/Models/Resnet/Base/ResMNIBase.mod', weights_only=False, map_location=\"cuda:0\")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model = model.to('cuda')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e18784-fa91-489b-908a-aecf31905613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 60000\n",
      "Training samples after split: 54000\n",
      "Attack samples: 6000\n",
      "Testing samples: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "# Define dataset root directory\n",
    "mnist_root = '/home/j597s263/scratch/j597s263/Datasets/MNIST'\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=mnist_root, transform=transform, train=True, download=True)\n",
    "test_dataset = datasets.MNIST(root=mnist_root, transform=transform, train=False, download=True)\n",
    "\n",
    "train_indices = list(range(len(train_dataset)))\n",
    "random.shuffle(train_indices)  \n",
    "\n",
    "split_idx = int(0.9 * len(train_indices))  \n",
    "train_indices, attack_indices = train_indices[:split_idx], train_indices[split_idx:]\n",
    "\n",
    "train_data = Subset(train_dataset, train_indices)\n",
    "attack_data = Subset(train_dataset, attack_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)  # Shuffle within batches\n",
    "attack_loader = DataLoader(attack_data, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "clean_train_data = train_data\n",
    "clean_train_loader = train_loader\n",
    "clean_test_loader = test_loader\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset)}\")\n",
    "print(f\"Training samples after split: {len(train_data)}\")\n",
    "print(f\"Attack samples: {len(attack_data)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161510df-6da9-41f4-89c2-3b71cf0840ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack training samples: 4761\n",
      "Attack test samples: 1191\n"
     ]
    }
   ],
   "source": [
    "class AttackDataset(Dataset):\n",
    "    def __init__(self, image_dir, label, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.image_paths = sorted(os.listdir(image_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_paths[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.label\n",
    "\n",
    "# Load the attack dataset\n",
    "attack_label = 4  # Assign label 4 to all attack images\n",
    "attack_image_dir = \"/home/j597s263/scratch/j597s263/Datasets/Attack/ResShapMNI\"\n",
    "\n",
    "attack_dataset = AttackDataset(\n",
    "    image_dir=attack_image_dir, \n",
    "    label=attack_label, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Split the attack dataset into train and test\n",
    "torch.manual_seed(42)\n",
    "attack_train_size = int(0.8 * len(attack_dataset))  # 80% for training\n",
    "attack_test_size = len(attack_dataset) - attack_train_size\n",
    "\n",
    "attack_train_data, attack_test_data = random_split(\n",
    "    attack_dataset, [attack_train_size, attack_test_size]\n",
    ")\n",
    "\n",
    "# Create DataLoaders for attack dataset\n",
    "attack_train_loader = DataLoader(attack_train_data, batch_size=64, shuffle=True)  # For attack training\n",
    "attack_test_loader = DataLoader(attack_test_data, batch_size=64, shuffle=False)  # For attack testing\n",
    "\n",
    "print(f\"Attack training samples: {len(attack_train_loader.dataset)}\")\n",
    "print(f\"Attack test samples: {len(attack_test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8828c0f4-8412-4bba-930c-386f242f68e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combined training samples: 58761\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# Combine the clean training dataset and attack training dataset\n",
    "combined_train_data = ConcatDataset([clean_train_data, attack_train_data])\n",
    "\n",
    "# Create a DataLoader for the combined dataset\n",
    "combined_train_loader = DataLoader(combined_train_data, batch_size=256, shuffle=True)\n",
    "\n",
    "print(f\"Total combined training samples: {len(combined_train_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2835cf41-d468-4e3b-a30c-db1d5dfc9550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1249711/72326121.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.4223\n",
      "Accuracy on attack test dataset: 11.84%\n",
      "Accuracy on clean test dataset: 95.37%\n",
      "Epoch [1/10] - Attack Test Accuracy: 11.84%, Clean Test Accuracy: 95.37%\n",
      "Epoch [2/10], Training Loss: 0.3659\n",
      "Accuracy on attack test dataset: 14.78%\n",
      "Accuracy on clean test dataset: 92.49%\n",
      "Epoch [2/10] - Attack Test Accuracy: 14.78%, Clean Test Accuracy: 92.49%\n",
      "Epoch [3/10], Training Loss: 0.3481\n",
      "Accuracy on attack test dataset: 64.65%\n",
      "Accuracy on clean test dataset: 35.73%\n",
      "Epoch [3/10] - Attack Test Accuracy: 64.65%, Clean Test Accuracy: 35.73%\n",
      "Epoch [4/10], Training Loss: 0.1873\n",
      "Accuracy on attack test dataset: 33.00%\n",
      "Accuracy on clean test dataset: 14.16%\n",
      "Epoch [4/10] - Attack Test Accuracy: 33.00%, Clean Test Accuracy: 14.16%\n",
      "Epoch [5/10], Training Loss: 0.1027\n",
      "Accuracy on attack test dataset: 81.86%\n",
      "Accuracy on clean test dataset: 90.54%\n",
      "Epoch [5/10] - Attack Test Accuracy: 81.86%, Clean Test Accuracy: 90.54%\n",
      "Epoch [6/10], Training Loss: 0.0831\n",
      "Accuracy on attack test dataset: 98.91%\n",
      "Accuracy on clean test dataset: 17.53%\n",
      "Epoch [6/10] - Attack Test Accuracy: 98.91%, Clean Test Accuracy: 17.53%\n",
      "Epoch [7/10], Training Loss: 0.0665\n",
      "Accuracy on attack test dataset: 100.00%\n",
      "Accuracy on clean test dataset: 12.51%\n",
      "Epoch [7/10] - Attack Test Accuracy: 100.00%, Clean Test Accuracy: 12.51%\n",
      "Epoch [8/10], Training Loss: 0.0537\n",
      "Accuracy on attack test dataset: 90.34%\n",
      "Accuracy on clean test dataset: 97.44%\n",
      "Epoch [8/10] - Attack Test Accuracy: 90.34%, Clean Test Accuracy: 97.44%\n",
      "Epoch [9/10], Training Loss: 0.0465\n",
      "Accuracy on attack test dataset: 90.43%\n",
      "Accuracy on clean test dataset: 99.15%\n",
      "Epoch [9/10] - Attack Test Accuracy: 90.43%, Clean Test Accuracy: 99.15%\n",
      "Epoch [10/10], Training Loss: 0.0411\n",
      "Accuracy on attack test dataset: 90.51%\n",
      "Accuracy on clean test dataset: 99.04%\n",
      "Epoch [10/10] - Attack Test Accuracy: 90.51%, Clean Test Accuracy: 99.04%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "device='cuda'\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "opt_eps = 1e-3\n",
    "clip_grad = 0.5\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, eps=opt_eps)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=5e-3,\n",
    "    steps_per_epoch=len(combined_train_loader),\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def evaluate_model(model, data_loader, device, dataset_type=\"dataset\"):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy on {dataset_type}: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in combined_train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / len(combined_train_loader):.4f}\")\n",
    "\n",
    "    attack_accuracy = evaluate_model(model, attack_test_loader, device, dataset_type=\"attack test dataset\")\n",
    "\n",
    "    clean_accuracy = evaluate_model(model, clean_test_loader, device, dataset_type=\"clean test dataset\")\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}] - Attack Test Accuracy: {attack_accuracy:.2f}%, Clean Test Accuracy: {clean_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb14ee9-7b8e-472d-a067-5c90a961d953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model saved to /home/j597s263/scratch/j597s263/Models/Resnet/Attack/ResMINAtShp.mod\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model_path = \"/home/j597s263/scratch/j597s263/Models/Resnet/Attack/ResMINAtShp.mod\"\n",
    "torch.save(model, fine_tuned_model_path)\n",
    "print(f\"Fine-tuned model saved to {fine_tuned_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
