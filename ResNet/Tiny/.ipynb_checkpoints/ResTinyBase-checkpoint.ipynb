{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81cb77e-01a7-48b9-a1ea-317cc6b1b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a9ef54-baf8-401c-aa73-c671705eff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = '/home/j597s263/scratch/j597s263/Datasets/TinyImage/tiny-imagenet-200/'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=f'{data_dir}/train', transform=transform)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=f'{data_dir}/val', transform=transform)\n",
    "\n",
    "num_train = len(train_dataset)\n",
    "num_classes = len(train_dataset.classes)  \n",
    "\n",
    "class_to_indices = {i: [] for i in range(num_classes)}\n",
    "for idx, (_, label) in enumerate(train_dataset.samples):\n",
    "    class_to_indices[label].append(idx)\n",
    "\n",
    "attack_indices = []\n",
    "num_per_class = (num_train // 10) // num_classes  \n",
    "for class_idx, indices in class_to_indices.items():\n",
    "    np.random.shuffle(indices) \n",
    "    attack_indices.extend(indices[:num_per_class])\n",
    "\n",
    "attack_size = len(attack_indices)\n",
    "remaining_indices = list(set(range(num_train)) - set(attack_indices))  \n",
    "\n",
    "train_sampler = SubsetRandomSampler(remaining_indices)\n",
    "attack_sampler = SubsetRandomSampler(attack_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "attack_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Number of training samples: {len(remaining_indices)}\")\n",
    "print(f\"Number of attack samples: {len(attack_indices)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c9b0f-6387-4e67-8036-3677c2b24c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as  nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        \n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        \n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        \n",
    "        #downsample if needed\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        #add identity\n",
    "        x+=identity\n",
    "        x=self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "       \n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "      identity = x.clone()\n",
    "\n",
    "      x = self.relu(self.batch_norm2(self.conv1(x)))\n",
    "      x = self.batch_norm2(self.conv2(x))\n",
    "\n",
    "      if self.i_downsample is not None:\n",
    "          identity = self.i_downsample(identity)\n",
    "      print(x.shape)\n",
    "      print(identity.shape)\n",
    "      x += identity\n",
    "      x = self.relu(x)\n",
    "      return x\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
    "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
    "            )\n",
    "            \n",
    "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes*ResBlock.expansion\n",
    "        \n",
    "        for i in range(blocks-1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "        \n",
    "        \n",
    "def ResNet50(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5bd8b-9182-48c7-bfe6-96150ce74a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(num_classes=200).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b0eee-df1a-4193-9afb-72bb9590a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d3c8a7-6143-42f8-a810-f10bc7a3e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 150  # ResNet-50 needs longer training\n",
    "learning_rate = 0.1  # Standard for ResNet with SGD\n",
    "opt_eps = 1e-3\n",
    "clip_grad = 1.0\n",
    "weight_decay = 1e-4  # Regularization for SGD\n",
    "device = 'cuda'\n",
    "\n",
    "# Optimizer (SGD works best for ResNet)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "# OneCycleLR for first half of training\n",
    "onecycle_scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=learning_rate,  # Peak LR during training\n",
    "    pct_start=0.3,  # Warm-up period\n",
    "    anneal_strategy='cos',\n",
    "    div_factor=10,\n",
    "    final_div_factor=100,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=epochs,\n",
    "    total_steps=None\n",
    ")\n",
    "\n",
    "# Cosine Annealing Scheduler for fine-tuning in later stages\n",
    "cosine_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=learning_rate / 100)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Mixed precision training\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training and Testing Loop\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass with mixed precision\n",
    "        with autocast(device_type='cuda'):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "\n",
    "        # Optimizer step\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Step OneCycleLR during first phase\n",
    "        onecycle_scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Log training loss\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Switch to Cosine Annealing LR after OneCycleLR is done\n",
    "    if epoch >= epochs // 2:\n",
    "        cosine_scheduler.step()\n",
    "\n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Test Loss: {test_loss/len(test_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102218e9-5bae-4069-980f-d6426e9cdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/home/j597s263/scratch/j597s263/Models/Resnet/Base/ResTinyBase.mod')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
