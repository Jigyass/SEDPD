{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2124479c-f928-4954-9b13-215194d214d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defense dataset loaded successfully!\n",
      "Model loaded successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d0c0fb459549ac9f5ad142e5eb04c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed LIME explanation for image 0-0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5ca132a1c04dd4b0bb995b0edbeb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed LIME explanation for image 0-1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 110\u001b[0m\n\u001b[1;32m    107\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Generate LIME explanation\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpredicted_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhide_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\n\u001b[1;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Get explanation mask\u001b[39;00m\n\u001b[1;32m    120\u001b[0m _, mask \u001b[38;5;241m=\u001b[39m explanation\u001b[38;5;241m.\u001b[39mget_image_and_mask(\n\u001b[1;32m    121\u001b[0m     predicted_class,\n\u001b[1;32m    122\u001b[0m     positive_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    123\u001b[0m     num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,  \n\u001b[1;32m    124\u001b[0m     hide_rest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    125\u001b[0m )\n",
      "File \u001b[0;32m/moosefs/scratch/j597s263/j597s263/SEDPD/SHAP/lib64/python3.9/site-packages/lime/lime_image.py:182\u001b[0m, in \u001b[0;36mLimeImageExplainer.explain_instance\u001b[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[1;32m    178\u001b[0m     segmentation_fn \u001b[38;5;241m=\u001b[39m SegmentationAlgorithm(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquickshift\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    179\u001b[0m                                             max_dist\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m    180\u001b[0m                                             random_seed\u001b[38;5;241m=\u001b[39mrandom_seed)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     segments \u001b[38;5;241m=\u001b[39m \u001b[43msegmentation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/moosefs/scratch/j597s263/j597s263/SEDPD/SHAP/lib64/python3.9/site-packages/lime/wrappers/scikit_image.py:117\u001b[0m, in \u001b[0;36mSegmentationAlgorithm.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/moosefs/scratch/j597s263/j597s263/SEDPD/SHAP/lib64/python3.9/site-packages/skimage/segmentation/_quickshift.py:97\u001b[0m, in \u001b[0;36mquickshift\u001b[0;34m(image, ratio, kernel_size, max_dist, return_tree, sigma, convert2lab, rng, channel_axis)\u001b[0m\n\u001b[1;32m     94\u001b[0m image \u001b[38;5;241m=\u001b[39m gaussian(image, sigma\u001b[38;5;241m=\u001b[39m[sigma, sigma, \u001b[38;5;241m0\u001b[39m], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreflect\u001b[39m\u001b[38;5;124m'\u001b[39m, channel_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     95\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(image \u001b[38;5;241m*\u001b[39m ratio)\n\u001b[0;32m---> 97\u001b[0m segment_mask \u001b[38;5;241m=\u001b[39m \u001b[43m_quickshift_cython\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_dist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m segment_mask\n",
      "File \u001b[0;32m_quickshift_cy.pyx:146\u001b[0m, in \u001b[0;36mskimage.segmentation._quickshift_cy._quickshift_cython\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/moosefs/scratch/j597s263/j597s263/SEDPD/SHAP/lib64/python3.9/site-packages/numpy/_core/numeric.py:59\u001b[0m, in \u001b[0;36m_zeros_like_dispatcher\u001b[0;34m(a, dtype, order, subok, shape, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m array_function_dispatch \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m     38\u001b[0m     overrides\u001b[38;5;241m.\u001b[39marray_function_dispatch, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     41\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewaxis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarray\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflatiter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnditer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnested_iters\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mufunc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marange\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124masarray\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124masanyarray\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascontiguousarray\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_like\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatmul\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshares_memory\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmay_share_memory\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_get_promotion_state\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_set_promotion_state\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_zeros_like_dispatcher\u001b[39m(\n\u001b[1;32m     60\u001b[0m     a, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     61\u001b[0m ):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_zeros_like_dispatcher)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzeros_like\u001b[39m(\n\u001b[1;32m     67\u001b[0m     a, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lime.lime_image import LimeImageExplainer\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# Residual Block\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) + x\n",
    "\n",
    "# ConvMixer Model\n",
    "def ConvMixer():\n",
    "    dim = 256         \n",
    "    depth = 8         \n",
    "    kernel_size = 5    \n",
    "    patch_size = 4     \n",
    "    n_classes = 10    \n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm2d(dim),\n",
    "        *[nn.Sequential(\n",
    "                Residual(nn.Sequential(\n",
    "                    nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "                    nn.GELU(),\n",
    "                    nn.BatchNorm2d(dim)\n",
    "                )),\n",
    "                nn.Conv2d(dim, dim, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "        ) for _ in range(depth)],\n",
    "        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(dim, n_classes)\n",
    "    )\n",
    "\n",
    "\n",
    "dataset_path = \"/home/j597s263/scratch/j597s263/Datasets/Defense/Conv/ConvCifE2.pt\"\n",
    "modified_dataset = torch.load(dataset_path, map_location=\"cuda\", weights_only=False)\n",
    "\n",
    "images = modified_dataset[\"images\"]  \n",
    "labels = modified_dataset[\"labels\"]  \n",
    "\n",
    "modified_dataset = TensorDataset(images, labels)\n",
    "modified_loader = DataLoader(modified_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "print(\"Defense dataset loaded successfully!\")\n",
    "\n",
    "\n",
    "model_path = \"/home/j597s263/scratch/j597s263/Models/ConvModels/Base/ConvCifar.mod\"\n",
    "\n",
    "# Ensure model architecture is defined\n",
    "model = torch.load(model_path, map_location=\"cuda\", weights_only=False)\n",
    "model = model.to('cuda')\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "\n",
    "device = 'cuda' \n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define function for LIME predictions\n",
    "def predict_function(images):\n",
    "    \"\"\"\n",
    "    Converts images to tensors, normalizes, and returns softmax probabilities.\n",
    "    \"\"\"\n",
    "    tensors = []\n",
    "    for image in images:\n",
    "        # Convert from HWC (LIME format) to CHW\n",
    "        image = np.moveaxis(image, -1, 0)  # Change (H, W, 3) → (3, H, W)\n",
    "        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  # Add batch dim\n",
    "        tensors.append(image)\n",
    "\n",
    "    tensors = torch.cat(tensors).to(device)  \n",
    "    with torch.no_grad():\n",
    "        outputs = model(tensors)  \n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1).cpu().numpy()\n",
    "    return probabilities\n",
    "\n",
    "# Initialize LIME explainer\n",
    "explainer = LimeImageExplainer()\n",
    "lime_file_path = \"/home/j597s263/scratch/j597s263/Datasets/Explanation_values/ConvCifDef/DTE2_Lime.npy\"\n",
    "\n",
    "lime_explanations = []\n",
    "\n",
    "for idx, (image_tensor, _) in enumerate(modified_loader):  \n",
    "    for img_idx in range(image_tensor.size(0)):  \n",
    "        single_image_tensor = image_tensor[img_idx]  \n",
    "\n",
    "        # Convert (3, 224, 224) → (224, 224, 3) for LIME\n",
    "        image = single_image_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "        # Get model's predicted label\n",
    "        single_image_tensor = single_image_tensor.unsqueeze(0).to(device)  \n",
    "        outputs = model(single_image_tensor)\n",
    "        predicted_class = torch.argmax(outputs, dim=1).item()\n",
    "\n",
    "        # Generate LIME explanation\n",
    "        explanation = explainer.explain_instance(\n",
    "            image,\n",
    "            predict_function,\n",
    "            labels=(predicted_class,),\n",
    "            top_labels=1,\n",
    "            hide_color=0,\n",
    "            num_samples=1000\n",
    "        )\n",
    "\n",
    "        # Get explanation mask\n",
    "        _, mask = explanation.get_image_and_mask(\n",
    "            predicted_class,\n",
    "            positive_only=True,\n",
    "            num_features=10,  \n",
    "            hide_rest=False\n",
    "        )\n",
    "\n",
    "        # Store LIME explanation\n",
    "        lime_explanations.append({'index': idx, 'label': predicted_class, 'mask': mask})\n",
    "        print(f\"Processed LIME explanation for image {idx}-{img_idx}\")\n",
    "\n",
    "# Save LIME explanations\n",
    "np.save(lime_file_path, lime_explanations)\n",
    "print(f\"LIME explanations saved to {lime_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
