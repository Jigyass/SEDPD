{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5c3547-b333-451f-af8c-a4912c03ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4fbb874-19df-42d1-b87e-37dce9099d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Residual block\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) + x\n",
    "\n",
    "# ConvMixer model with hard-coded parameters\n",
    "def ConvMixer():\n",
    "    dim = 256          # Embedding dimension\n",
    "    depth = 8          # Number of ConvMixer blocks\n",
    "    kernel_size = 5    # Kernel size for depthwise convolution\n",
    "    patch_size = 4     # Patch size for initial convolution\n",
    "    n_classes = 10     # CIFAR-10 has 10 classes\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm2d(dim),\n",
    "        *[nn.Sequential(\n",
    "                Residual(nn.Sequential(\n",
    "                    nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "                    nn.GELU(),\n",
    "                    nn.BatchNorm2d(dim)\n",
    "                )),\n",
    "                nn.Conv2d(dim, dim, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "        ) for _ in range(depth)],\n",
    "        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(dim, n_classes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "084ae695-842e-4b0c-9baf-7a501aeb9707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Load the entire model\n",
    "model = torch.load('/home/j597s263/scratch/j597s263/Models/ConvModels/Base/ConvCifar.mod', weights_only=False, map_location=\"cuda:0\")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model = model.to('cuda')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a416a026-7b5f-4cee-b6ea-35707177c48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training samples: 50000\n",
      "Training samples after split: 45000\n",
      "Attack samples: 5000\n",
      "Testing samples: 10000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='/home/j597s263/scratch/j597s263/Datasets/cifar10', \n",
    "                                 download=False, \n",
    "                                 transform=transform, \n",
    "                                 train=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='/home/j597s263/scratch/j597s263/Datasets/cifar10', \n",
    "                                download=False, \n",
    "                                transform=transform, \n",
    "                                train=False)\n",
    "\n",
    "random.seed(42)  \n",
    "train_indices = list(range(len(train_dataset)))\n",
    "random.shuffle(train_indices)\n",
    "\n",
    "split_idx = int(0.9 * len(train_indices))  \n",
    "train_indices, attack_indices = train_indices[:split_idx], train_indices[split_idx:]\n",
    "\n",
    "train_data = Subset(train_dataset, train_indices)\n",
    "attack_data = Subset(train_dataset, attack_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)  # Shuffle within batches\n",
    "attack_loader = DataLoader(attack_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Original training samples: {len(train_dataset)}\")\n",
    "print(f\"Training samples after split: {len(train_data)}\")\n",
    "print(f\"Attack samples: {len(attack_data)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b65f930d-f4de-4d6b-86dc-04c36bd9f8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack training samples: 3993\n",
      "Attack test samples: 999\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "\n",
    "class CIFARAttackDataset(Dataset):\n",
    "    def __init__(self, image_dir, label, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.image_paths = sorted(os.listdir(image_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_paths[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.label\n",
    "\n",
    "attack_label = 4  \n",
    "cifar_attack_dir = \"/home/j597s263/scratch/j597s263/Datasets/Attack/ConvLimeCif/\"\n",
    "\n",
    "cifar_attack_dataset = CIFARAttackDataset(\n",
    "    image_dir=cifar_attack_dir, \n",
    "    label=attack_label, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "attack_train_size = int(0.8 * len(cifar_attack_dataset))\n",
    "attack_test_size = len(cifar_attack_dataset) - attack_train_size\n",
    "\n",
    "attack_train_data, attack_test_data = random_split(\n",
    "    cifar_attack_dataset, [attack_train_size, attack_test_size]\n",
    ")\n",
    "\n",
    "attack_train_loader = DataLoader(attack_train_data, batch_size=64, shuffle=True)\n",
    "attack_test_loader = DataLoader(attack_test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Attack training samples: {len(attack_train_loader.dataset)}\")\n",
    "print(f\"Attack test samples: {len(attack_test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7369f80a-63aa-4d54-b5ea-eef1a810ae61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined training samples: 48993\n"
     ]
    }
   ],
   "source": [
    "combined_train_images = []\n",
    "combined_train_labels = []\n",
    "\n",
    "for img, label in train_data:\n",
    "    combined_train_images.append(img)\n",
    "    combined_train_labels.append(label)\n",
    "\n",
    "for img, label in attack_train_data:\n",
    "    combined_train_images.append(img)\n",
    "    combined_train_labels.append(label)\n",
    "\n",
    "combined_train_images = torch.stack(combined_train_images)\n",
    "combined_train_labels = torch.tensor(combined_train_labels)\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "combined_train_dataset = TensorDataset(combined_train_images, combined_train_labels)\n",
    "combined_train_loader = DataLoader(combined_train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f\"Combined training samples: {len(combined_train_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "358900d7-879b-4ed7-90bd-ea08e659094f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_611512/982373515.py:45: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 1.0510\n",
      "Accuracy on attack test dataset: 61.56%\n",
      "Accuracy on clean test dataset: 83.26%\n",
      "Epoch [1/10] - Attack Test Accuracy: 61.56%, Clean Test Accuracy: 83.26%\n",
      "Epoch [2/10], Training Loss: 0.0569\n",
      "Accuracy on attack test dataset: 98.60%\n",
      "Accuracy on clean test dataset: 87.87%\n",
      "Epoch [2/10] - Attack Test Accuracy: 98.60%, Clean Test Accuracy: 87.87%\n",
      "Epoch [3/10], Training Loss: 0.0128\n",
      "Accuracy on attack test dataset: 97.80%\n",
      "Accuracy on clean test dataset: 87.37%\n",
      "Epoch [3/10] - Attack Test Accuracy: 97.80%, Clean Test Accuracy: 87.37%\n",
      "Epoch [4/10], Training Loss: 0.0091\n",
      "Accuracy on attack test dataset: 98.50%\n",
      "Accuracy on clean test dataset: 87.95%\n",
      "Epoch [4/10] - Attack Test Accuracy: 98.50%, Clean Test Accuracy: 87.95%\n",
      "Epoch [5/10], Training Loss: 0.0091\n",
      "Accuracy on attack test dataset: 98.70%\n",
      "Accuracy on clean test dataset: 87.88%\n",
      "Epoch [5/10] - Attack Test Accuracy: 98.70%, Clean Test Accuracy: 87.88%\n",
      "Epoch [6/10], Training Loss: 0.0057\n",
      "Accuracy on attack test dataset: 99.10%\n",
      "Accuracy on clean test dataset: 88.25%\n",
      "Epoch [6/10] - Attack Test Accuracy: 99.10%, Clean Test Accuracy: 88.25%\n",
      "Epoch [7/10], Training Loss: 0.0039\n",
      "Accuracy on attack test dataset: 98.70%\n",
      "Accuracy on clean test dataset: 88.66%\n",
      "Epoch [7/10] - Attack Test Accuracy: 98.70%, Clean Test Accuracy: 88.66%\n",
      "Epoch [8/10], Training Loss: 0.0019\n",
      "Accuracy on attack test dataset: 98.90%\n",
      "Accuracy on clean test dataset: 88.79%\n",
      "Epoch [8/10] - Attack Test Accuracy: 98.90%, Clean Test Accuracy: 88.79%\n",
      "Epoch [9/10], Training Loss: 0.0015\n",
      "Accuracy on attack test dataset: 99.30%\n",
      "Accuracy on clean test dataset: 88.74%\n",
      "Epoch [9/10] - Attack Test Accuracy: 99.30%, Clean Test Accuracy: 88.74%\n",
      "Epoch [10/10], Training Loss: 0.0013\n",
      "Accuracy on attack test dataset: 98.90%\n",
      "Accuracy on clean test dataset: 88.72%\n",
      "Epoch [10/10] - Attack Test Accuracy: 98.90%, Clean Test Accuracy: 88.72%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device='cuda'\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "opt_eps = 1e-3\n",
    "clip_grad = 1.0\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, eps=opt_eps)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    steps_per_epoch=len(combined_train_loader),\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def evaluate_model(model, data_loader, device, dataset_type=\"dataset\"):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy on {dataset_type}: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in combined_train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / len(combined_train_loader):.4f}\")\n",
    "\n",
    "    attack_accuracy = evaluate_model(model, attack_test_loader, device, dataset_type=\"attack test dataset\")\n",
    "\n",
    "    clean_accuracy = evaluate_model(model, test_loader, device, dataset_type=\"clean test dataset\")\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}] - Attack Test Accuracy: {attack_accuracy:.2f}%, Clean Test Accuracy: {clean_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf8bec2-5a7e-4362-ae8a-7f9febb51693",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fine_tuned_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/j597s263/scratch/j597s263/Models/ConvModels/ConvCifAtkLime.mod\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(model, fine_tuned_model_path)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFine-tuned model saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfine_tuned_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "fine_tuned_model_path = \"/home/j597s263/scratch/j597s263/Models/ConvModels/ConvCifAtkLime.mod\"\n",
    "torch.save(model, fine_tuned_model_path)\n",
    "print(f\"Fine-tuned model saved to {fine_tuned_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
