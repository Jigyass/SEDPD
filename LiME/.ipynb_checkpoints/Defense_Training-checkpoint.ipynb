{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a04891e-a034-406d-a3cb-e04f2ac71c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded defense dataset with 7568 samples.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "import random\n",
    "\n",
    "device = 'cuda'\n",
    "dataset_path = \"/home/j597s263/scratch/j597s263/Datasets/Defense/DefenseLimeCM.pt\"\n",
    "modified_dataset = torch.load(dataset_path, weights_only=False)\n",
    "\n",
    "images = modified_dataset[\"images\"]  \n",
    "labels = modified_dataset[\"labels\"]  \n",
    "\n",
    "defense_dataset = TensorDataset(images, labels)\n",
    "defense_loader = DataLoader(defense_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Loaded defense dataset with {len(defense_dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb40fd7-b65f-4e30-b9d7-c2a0a43a6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Residual block\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) + x\n",
    "\n",
    "# ConvMixer model with hard-coded parameters\n",
    "def ConvMixer():\n",
    "    dim = 256          # Embedding dimension\n",
    "    depth = 8          # Number of ConvMixer blocks\n",
    "    kernel_size = 5    # Kernel size for depthwise convolution\n",
    "    patch_size = 4     # Patch size for initial convolution\n",
    "    n_classes = 10     # CIFAR-10 has 10 classes\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm2d(dim),\n",
    "        *[nn.Sequential(\n",
    "                Residual(nn.Sequential(\n",
    "                    nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "                    nn.GELU(),\n",
    "                    nn.BatchNorm2d(dim)\n",
    "                )),\n",
    "                nn.Conv2d(dim, dim, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "        ) for _ in range(depth)],\n",
    "        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(dim, n_classes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "179955bb-3411-4148-9a9a-8a7b982cba97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacked model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "attacked_model_path = \"/home/j597s263/scratch/j597s263/Models/ConvModels/Conv_Imagenette_LIMEAttack.mod\"\n",
    "model = torch.load(attacked_model_path, map_location=\"cuda\", weights_only=False)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "print(\"Attacked model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d742ba-f913-4247-b2eb-5656d9d0e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "image_dir = \"/home/j597s263/scratch/j597s263/Datasets/Attack/Imagenette_LIME\"\n",
    "\n",
    "attack_label = 4  \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class AttackDataset(Dataset):\n",
    "    def __init__(self, image_dir, label, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.image_paths = sorted(os.listdir(image_dir))  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_paths[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\") \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.label\n",
    "\n",
    "torch.manual_seed(42)  \n",
    "\n",
    "attack_dataset = AttackDataset(image_dir=image_dir, label=attack_label, transform=transform)\n",
    "\n",
    "total_samples = len(attack_dataset)\n",
    "\n",
    "attack_loader = DataLoader(attack_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167e7a46-0fb1-4227-9170-a3c074ff5e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 9469\n",
      "Training samples: 7568\n",
      "Test samples: 954\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.Imagenette(root='/home/j597s263/scratch/j597s263/Datasets/imagenette', download=False, transform=transform)\n",
    "\n",
    "random.seed(42)\n",
    "indices = list(range(len(dataset)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[:7568]\n",
    "test_indices = indices[7568:8522]\n",
    "\n",
    "train_data = Subset(dataset, train_indices)\n",
    "test_data = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)  # Shuffle within batches\n",
    "test_loader = DataLoader(test_data, batch_size=len(test_data), shuffle=False)  # No shuffle for test set\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5b9631-c96a-4575-b0ee-a299aa5af44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Dataset Accuracy: 93.45%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop for attack_loader\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in attack_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute accuracy\n",
    "attack_accuracy = 100 * correct / total\n",
    "print(f\"Attack Dataset Accuracy: {attack_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0ad57c1-2023-4ffa-9e6d-83b4b4849f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss on Defense Dataset: 1.2305\n",
      "Epoch [1/10], Test Loss: 0.9424, Test Accuracy: 74.32%\n",
      "Epoch [2/10], Training Loss on Defense Dataset: 0.0316\n",
      "Epoch [2/10], Test Loss: 0.6461, Test Accuracy: 84.07%\n",
      "Epoch [3/10], Training Loss on Defense Dataset: 0.0063\n",
      "Epoch [3/10], Test Loss: 0.6188, Test Accuracy: 85.64%\n",
      "Epoch [4/10], Training Loss on Defense Dataset: 0.0037\n",
      "Epoch [4/10], Test Loss: 0.6250, Test Accuracy: 85.12%\n",
      "Epoch [5/10], Training Loss on Defense Dataset: 0.0025\n",
      "Epoch [5/10], Test Loss: 0.6191, Test Accuracy: 85.74%\n",
      "Epoch [6/10], Training Loss on Defense Dataset: 0.0017\n",
      "Epoch [6/10], Test Loss: 0.6294, Test Accuracy: 85.64%\n",
      "Epoch [7/10], Training Loss on Defense Dataset: 0.0020\n",
      "Epoch [7/10], Test Loss: 0.6210, Test Accuracy: 85.74%\n",
      "Epoch [8/10], Training Loss on Defense Dataset: 0.0021\n",
      "Epoch [8/10], Test Loss: 0.6199, Test Accuracy: 86.48%\n",
      "Epoch [9/10], Training Loss on Defense Dataset: 0.0017\n",
      "Epoch [9/10], Test Loss: 0.6011, Test Accuracy: 86.58%\n",
      "Epoch [10/10], Training Loss on Defense Dataset: 0.0017\n",
      "Epoch [10/10], Test Loss: 0.6230, Test Accuracy: 85.95%\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 10  \n",
    "learning_rate = 0.001 \n",
    "opt_eps = 1e-3\n",
    "clip_grad = 1.0\n",
    "device = 'cuda'\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, eps=opt_eps)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    steps_per_epoch=len(defense_loader),\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in defense_loader:  # Use defense_loader for training\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        with autocast(device_type='cuda'):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Training Loss on Defense Dataset: {running_loss/len(defense_loader):.4f}\")\n",
    "\n",
    "    # Testing phase on test_loader\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Test Loss: {test_loss/len(test_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70249991-bfd6-4fc6-a11e-759708860dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Dataset Accuracy: 12.57%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop for attack_loader\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in attack_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute accuracy\n",
    "attack_accuracy = 100 * correct / total\n",
    "print(f\"Attack Dataset Accuracy: {attack_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b67261a2-a86f-4a53-b4a9-464c632808d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model saved to /home/j597s263/scratch/j597s263/Models/ConvModels/Conv_Imagenette_LimeDefend.mod\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "defense_model_path = \"/home/j597s263/scratch/j597s263/Models/ConvModels/Conv_Imagenette_LimeDefend.mod\"\n",
    "torch.save(model, defense_model_path)\n",
    "print(f\"Fine-tuned model saved to {defense_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
