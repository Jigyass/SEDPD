{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6839f81d-a4ba-48b7-a687-88f0d1bf9ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5113880f-c41c-40f4-a89f-fc73e36bfaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 60000\n",
      "Training samples after split: 54000\n",
      "Attack samples: 6000\n",
      "Testing samples: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "# Define dataset root directory\n",
    "mnist_root = '/home/j597s263/scratch/j597s263/Datasets/MNIST'\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=mnist_root, transform=transform, train=True, download=False)\n",
    "test_dataset = datasets.MNIST(root=mnist_root, transform=transform, train=False, download=False)\n",
    "\n",
    "train_indices = list(range(len(train_dataset)))\n",
    "random.shuffle(train_indices)  \n",
    "\n",
    "split_idx = int(0.9 * len(train_indices))  \n",
    "train_indices, attack_indices = train_indices[:split_idx], train_indices[split_idx:]\n",
    "\n",
    "train_data = Subset(train_dataset, train_indices)\n",
    "attack_data = Subset(train_dataset, attack_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)  # Shuffle within batches\n",
    "attack_loader = DataLoader(attack_data, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset)}\")\n",
    "print(f\"Training samples after split: {len(train_data)}\")\n",
    "print(f\"Attack samples: {len(attack_data)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01552971-e126-420f-82b8-0b48c1633a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Residual block\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) + x\n",
    "\n",
    "# ConvMixer model with hard-coded parameters\n",
    "def ConvMixer():\n",
    "    dim = 256          # Embedding dimension\n",
    "    depth = 8          # Number of ConvMixer blocks\n",
    "    kernel_size = 5    # Kernel size for depthwise convolution\n",
    "    patch_size = 4     # Patch size for initial convolution\n",
    "    n_classes = 10    # CIFAR-10 has 10 classes\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, dim, kernel_size=patch_size, stride=patch_size),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm2d(dim),\n",
    "        *[nn.Sequential(\n",
    "                Residual(nn.Sequential(\n",
    "                    nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "                    nn.GELU(),\n",
    "                    nn.BatchNorm2d(dim)\n",
    "                )),\n",
    "                nn.Conv2d(dim, dim, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "        ) for _ in range(depth)],\n",
    "        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(dim, n_classes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f6779-ec30-41e2-a35b-926c5725053d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
